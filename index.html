<!DOCTYPE html>
<html data-bs-theme="light" lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, shrink-to-fit=no">
    <title>Dmitry Kovalev</title>
    <script type="application/ld+json">
        {
            "@context": "http://schema.org",
            "@type": "WebSite",
            "name": "Dmitry Kovalev",
            "url": "https://www.dmitry-kovalev.com"
        }
    </script>
    <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
    <link rel="stylesheet" href="assets/fonts/fontawesome-all.min.css">
    <link rel="stylesheet" href="assets/fonts/font-awesome.min.css">
    <link rel="stylesheet" href="assets/fonts/fontawesome5-overrides.min.css">
    <link rel="stylesheet" href="assets/css/styles.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
</head>

<body>
    <nav class="navbar navbar-expand-lg fixed-top bg-body" style="box-shadow: 0px 3px 5px;">
        <div class="container"><a class="navbar-brand" href="https://www.dmitry-kovalev.com">Dmitry Kovalev</a><button data-bs-toggle="collapse" class="navbar-toggler" data-bs-target="#navcol"><span class="visually-hidden">Toggle navigation</span><span class="navbar-toggler-icon"></span></button>
            <div class="collapse navbar-collapse" id="navcol">
                <ul class="navbar-nav">
                    <li class="nav-item"><a class="nav-link" href="#home" onclick="navbar_link_click();">Home</a></li>
                    <li class="nav-item"><a class="nav-link" href="#experience" onclick="navbar_link_click();">Experience</a></li>
                    <li class="nav-item"><a class="nav-link" href="#publications" onclick="navbar_link_click();">Publications</a></li>
                    <li class="nav-item"><a class="nav-link" href="#preprints" onclick="navbar_link_click();">Preprints</a></li>
                    <li class="nav-item"><a class="nav-link" href="#contact" onclick="navbar_link_click();">Contact</a></li>
                    <li class="nav-item"><a class="nav-link" href="CV2/CV.pdf">CV</a></li>
                </ul>
            </div>
        </div>
    </nav>
    <section id="home">
        <div class="div-section">
            <div class="container">
                <div class="row">
                    <div class="col-lg-4">
                        <div class="div-profile"><img class="image-avatar" src="assets/img/avatar_sqr.jpg">
                            <div>
                                <h2>Dmitry Kovalev</h2>
                            </div>
                            <div>
                                <h3>Senior Researcher</h3>
                            </div>
                            <div>
                                <h3><a href="https://research.yandex.com">Yandex Research</a></h3>
                            </div>
                            <div class="div-icons"><a href="https://scholar.google.com/citations?user=qHFA5z4AAAAJ"><i class="fa fa-star ai ai-google-scholar"></i></a><a href="https://www.linkedin.com/in/dakovalev1/"><i class="fab fa-linkedin"></i></a><a href="https://orcid.org/0000-0003-1467-2994"><i class="fa fa-star ai ai-orcid"></i></a><a href="mailto:dakovalev1@gmail.com"><i class="fas fa-envelope"></i></a><a href="CV2/CV.pdf"><i class="fa fa-star ai ai-cv"></i></a></div>
                        </div>
                    </div>
                    <div class="col">
                        <div>
                            <div class="row">
                                <div class="col">
                                    <div class="div-bio">
                                        <h1>Bio</h1>
                                        <p>I'm a senior researcher at <a href="https://research.yandex.com">Yandex Research</a> studying optimization algorithms. Before joining Yandex I did a postdoc at the <a href="https://uclouvain.be/en/index.html">Université catholique de Louvain</a> with <a href="https://scholar.google.com/citations?user=DJ8Ep8YAAAAJ">Yurii Nesterov</a>. I received my PhD in Computer Science at the <a href="https://www.kaust.edu.sa/en">King Abdullah University of Science and Technology</a>, where I worked in the <a href="https://vcc.kaust.edu.sa/Pages/Home.aspx">Visual Computing Center</a> under the supervision of <a href="https://richtarik.org">Peter Richtárik</a>. Prior to that I got my BS degree in Applied Mathematics and Physics at the <a href="https://mipt.ru/en">Moscow Institute of Physics and Technology</a> under the supervision of <a href="https://scholar.google.com/citations?user=AmeE8qkAAAAJ">Alexander Gasnikov</a>.</p>
                                    </div>
                                </div>
                            </div>
                            <div class="row">
                                <div class="col-lg-5">
                                    <div class="div-interests">
                                        <h3>Interests</h3>
                                        <ul>
                                            <li>Optimization</li>
                                            <li>Federated and Distributed Learning</li>
                                            <li>Machine Learning</li>
                                        </ul>
                                    </div>
                                </div>
                                <div class="col-lg-7">
                                    <div class="div-education">
                                        <h3>Education</h3>
                                        <ul>
                                            <li><span class="degree">PhD in Computer Science, 2022</span><a class="institution" href="https://www.kaust.edu.sa/en/">King Abdullah University of Science and Technology</a></li>
                                            <li><span class="degree">MS in Applied Mathematics and Physics, 2021</span><a class="institution" href="https://mipt.ru/en">Moscow Institute of Physics and Technology</a></li>
                                            <li><span class="degree">MS in Computer Science, 2019</span><a class="institution" href="https://www.kaust.edu.sa/en/">King Abdullah University of Science and Technology</a></li>
                                            <li><span class="degree">BS in Applied Mathematics and Physics, 2018</span><a class="institution" href="https://mipt.ru/en">Moscow Institute of Physics and Technology</a></li>
                                        </ul>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section id="experience">
        <div class="div-section div-section-dark">
            <div class="container">
                <div class="row">
                    <div class="col-lg-4">
                        <h1 class="h-section">Experience</h1>
                    </div>
                    <div class="col">
                        <div class="div-experience">
                            <h3 class="position">Senior Researcher</h3>
                            <h3 class="organization"><a href="https://research.yandex.com/">Yandex Research</a></h3>
                            <h3 class="location">2023 – Now • Moscow, Russia</h3>
                        </div>
                        <div class="div-experience">
                            <h3 class="position">Postdoctoral Researcher</h3>
                            <h3 class="organization"><a href="https://uclouvain.be/en/index.html">Université catholique de Louvain</a></h3>
                            <h3 class="location">2022 – 2023 • Brussels, Belgium</h3>
                        </div>
                        <div class="div-experience">
                            <h3 class="position">Research Intern</h3>
                            <h3 class="organization"><a href="https://www.ispras.ru/en/">Institute for System Programming</a></h3>
                            <h3 class="location">2021 – 2023 • Moscow, Russia</h3>
                        </div>
                        <div class="div-experience">
                            <h3 class="position">Researcher</h3>
                            <h3 class="organization"><a href="https://mipt.ru/en">Moscow Institute of Physics and Technology</a></h3>
                            <h3 class="location"><span style="color: var(--bs-gray);">2022</span> <span style="color: var(--bs-gray);">•</span> <span style="color: var(--bs-gray);">Moscow, Russia</span></h3>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section id="publications">
        <div class="div-section">
            <div class="container">
                <div class="row">
                    <div class="col-lg-4">
                        <h1 class="h-section">Publications</h1>
                    </div>
                    <div class="col">
                        <h3>2024</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://link.springer.com/article/10.1007/s10287-023-00493-9">Decentralized convex optimization on time-varying networks with application to Wasserstein barycenters</a></span><span> (Olga Yufereva, Michael Persiianov, Pavel Dvurechensky, Alexander Gasnikov, Dmitry Kovalev). Computational Management Science, 2024.<br/><div style="display:inline-block"><a class="paper-link" href="https://link.springer.com/article/10.1007/s10287-023-00493-9">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2205.15669">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2205.15669">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://link.springer.com/article/10.1007/s10287-023-00485-9">Decentralized saddle-point problems with different constants of strong convexity and strong concavity</a></span><span> (Dmitry Metelev, Alexander Rogozin, Alexander Gasnikov, Dmitry Kovalev). Computational Management Science, 2024.<br/><div style="display:inline-block"><a class="paper-link" href="https://link.springer.com/article/10.1007/s10287-023-00485-9">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2206.00090">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2206.00090">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://www.tandfonline.com/doi/abs/10.1080/10556788.2023.2280062">Decentralized saddle point problems via non-Euclidean mirror prox</a></span><span> (Alexander Rogozin, Aleksandr Beznosikov, Darina Dvinskikh, Dmitry Kovalev, Pavel Dvurechensky, Alexander Gasnikov). Optimization Methods and Software, 2024.<br/><div style="display:inline-block"><a class="paper-link" href="https://www.tandfonline.com/doi/abs/10.1080/10556788.2023.2280062">Link<i class="fa fa-solid fa-link"></i></a></div></span></div>

                        <h3>2023</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://link.springer.com/article/10.1007/s10287-023-00479-7">Non-smooth setting of stochastic decentralized convex optimization problem over time-varying graphs</a></span><span> (Aleksandr Lobanov, Andrew Veprikov, Georgiy Konin, Aleksandr Beznosikov, Alexander Gasnikov, Dmitry Kovalev). Computational Management Science, 2023.<br/><div style="display:inline-block"><a class="paper-link" href="https://link.springer.com/article/10.1007/s10287-023-00479-7">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2307.00392">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2307.00392">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://link.springer.com/content/pdf/10.1007/978-3-030-54621-2_860-1.pdf">Decentralized Convex Optimization over Time-Varying Graphs</a></span><span> (Alexander Rogozin, Alexander Gasnikov, Aleksander Beznosikov, Dmitry Kovalev). Encyclopedia of Optimization, 2023.<br/><div style="display:inline-block"><a class="paper-link" href="https://link.springer.com/content/pdf/10.1007/978-3-030-54621-2_860-1.pdf">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2210.09719">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2210.09719">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://ems.press/journals/mag/articles/9939904">Smooth monotone stochastic variational inequalities and saddle point problems: A survey</a></span><span> (Aleksandr Beznosikov, Boris Polyak, Eduard Gorbunov, Dmitry Kovalev, Alexander Gasnikov). European Mathematical Society Magazine, 2023.<br/><div style="display:inline-block"><a class="paper-link" href="https://ems.press/journals/mag/articles/9939904">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2208.13592">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2208.13592">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.mlr.press/v202/metelev23a.html">Is consensus acceleration possible in decentralized optimization over slowly time-varying networks?</a></span><span> (Dmitry Metelev, Alexander Rogozin, Dmitry Kovalev, Alexander Gasnikov). International Conference on Machine Learning, 2023.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.mlr.press/v202/metelev23a.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2301.11817">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2301.11817">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://www.tandfonline.com/doi/abs/10.1080/10556788.2022.2117355">Stochastic distributed learning with gradient quantization and double-variance reduction</a></span><span> (Samuel Horváth, Dmitry Kovalev, Konstantin Mishchenko, Peter Richtárik, Sebastian Stich). Optimization Methods and Software, 2023.<br/><div style="display:inline-block"><a class="paper-link" href="https://www.tandfonline.com/doi/abs/10.1080/10556788.2022.2117355">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/1904.05115">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/1904.05115">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>

                        <h3>2022</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/883f66687a521536c505f9b2fbdcbf1e-Abstract-Conference.html">Accelerated primal-dual gradient method for smooth and convex-concave saddle-point problems with bilinear coupling</a></span><span> (Dmitry Kovalev, Alexander Gasnikov, Peter Richtárik). Advances in Neural Information Processing Systems, 2022.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/883f66687a521536c505f9b2fbdcbf1e-Abstract-Conference.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2112.15199">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2112.15199">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/88c3c482430a62d35e03926a22e4b67e-Abstract-Conference.html">Communication acceleration of local gradient methods via an accelerated primal-dual algorithm with an inexact prox</a></span><span> (Abdurakhmon Sadiev, Dmitry Kovalev, Peter Richtárik). Advances in Neural Information Processing Systems, 2022.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/88c3c482430a62d35e03926a22e4b67e-Abstract-Conference.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2207.03957">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2207.03957">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/c959bb2cb164d37569a17fa67494d69a-Abstract-Conference.html">Optimal algorithms for decentralized stochastic variational inequalities</a></span><span> (Dmitry Kovalev, Aleksandr Beznosikov, Abdurakhmon Sadiev, Michael Persiianov, Peter Richtárik, Alexander Gasnikov). Advances in Neural Information Processing Systems, 2022.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/c959bb2cb164d37569a17fa67494d69a-Abstract-Conference.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2202.02771">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2202.02771">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/d88f6f81e1aaf606776ffdd06fdf24ef-Abstract-Conference.html">Optimal gradient sliding and its application to optimal distributed optimization under similarity</a></span><span> (Dmitry Kovalev, Aleksandr Beznosikov, Ekaterina Borodich, Alexander Gasnikov, Gesualdo Scutari). Advances in Neural Information Processing Systems, 2022.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/d88f6f81e1aaf606776ffdd06fdf24ef-Abstract-Conference.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2205.15136">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2205.15136">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/e56f394bbd4f0ec81393d767caa5a31b-Abstract-Conference.html">The first optimal acceleration of high-order methods in smooth convex optimization</a></span><span> (Dmitry Kovalev, Alexander Gasnikov). Advances in Neural Information Processing Systems, 2022.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/e56f394bbd4f0ec81393d767caa5a31b-Abstract-Conference.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2205.09647">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2205.09647">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/5e2ed801f62102f531d109d7c6e1b62f-Abstract-Conference.html">The first optimal algorithm for smooth and strongly-convex-strongly-concave minimax optimization</a></span><span> (Dmitry Kovalev, Alexander Gasnikov). Advances in Neural Information Processing Systems, 2022.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/5e2ed801f62102f531d109d7c6e1b62f-Abstract-Conference.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2205.05653">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2205.05653">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="http://crm-en.ics.org.ru/uploads/crmissues/crm_2023_02/22_tominin.pdf">Accelerated variance-reduced methods for saddle-point problems</a></span><span> (Ekaterina Borodich, Vladislav Tominin, Yaroslav Tominin, Dmitry Kovalev, Alexander Gasnikov, Pavel Dvurechensky). EURO Journal on Computational Optimization, 2022.<br/><div style="display:inline-block"><a class="paper-link" href="http://crm-en.ics.org.ru/uploads/crmissues/crm_2023_02/22_tominin.pdf">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2103.09344">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2103.09344">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.mlr.press/v151/salim22a.html">An optimal algorithm for strongly convex minimization under affine constraints</a></span><span> (Adil Salim, Laurent Condat, Dmitry Kovalev, Peter Richtárik). International Conference on Artificial Intelligence and Statistics, 2022.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.mlr.press/v151/salim22a.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2102.11079">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2102.11079">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title">IntSGD: Adaptive floatless compression of stochastic gradients</span><span> (Konstantin Mishchenko, Bokun Wang, Dmitry Kovalev, Peter Richtárik). International Conference on Learning Representations, 2022.<br/><div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2102.08374">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2102.08374">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>

                        <h3>2021</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.neurips.cc/paper/2021/hash/bc37e109d92bdc1ea71da6c919d54907-Abstract.html">Lower bounds and optimal algorithms for smooth and strongly convex decentralized optimization over time-varying networks</a></span><span> (Dmitry Kovalev, Elnur Gasanov, Alexander Gasnikov, Peter Richtarik). Advances in Neural Information Processing Systems, 2021.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.neurips.cc/paper/2021/hash/bc37e109d92bdc1ea71da6c919d54907-Abstract.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2106.04469">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2106.04469">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.mlr.press/v130/kovalev21a.html">A linearly convergent algorithm for decentralized optimization: Sending less bits for free!</a></span><span> (Dmitry Kovalev, Anastasia Koloskova, Martin Jaggi, Peter Richtarik, Sebastian Stich). International Conference on Artificial Intelligence and Statistics, 2021.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.mlr.press/v130/kovalev21a.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2011.01697">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2011.01697">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="http://proceedings.mlr.press/v139/kovalev21a">ADOM: accelerated decentralized optimization method for time-varying networks</a></span><span> (Dmitry Kovalev, Egor Shulgin, Peter Richtárik, Alexander V Rogozin, Alexander Gasnikov). International Conference on Machine Learning, 2021.<br/><div style="display:inline-block"><a class="paper-link" href="http://proceedings.mlr.press/v139/kovalev21a">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2102.09234">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2102.09234">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://link.springer.com/chapter/10.1007/978-3-030-91059-4_18">Near-optimal decentralized algorithms for saddle point problems over time-varying networks</a></span><span> (Aleksandr Beznosikov, Alexander Rogozin, Dmitry Kovalev, Alexander Gasnikov). Optimization and Applications: 12th International Conference, OPTIMA 2021, Petrovac, Montenegro, September 27–October 1, 2021, Proceedings 12, 2021.<br/><div style="display:inline-block"><a class="paper-link" href="https://link.springer.com/chapter/10.1007/978-3-030-91059-4_18">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2107.05957">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2107.05957">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://link.springer.com/chapter/10.1007/978-3-030-91059-4_19">Towards accelerated rates for distributed optimization over time-varying networks</a></span><span> (Alexander Rogozin, Vladislav Lukoshkin, Alexander Gasnikov, Dmitry Kovalev, Egor Shulgin). Optimization and Applications: 12th International Conference, OPTIMA 2021, Petrovac, Montenegro, September 27–October 1, 2021, Proceedings 12, 2021.<br/><div style="display:inline-block"><a class="paper-link" href="https://link.springer.com/chapter/10.1007/978-3-030-91059-4_19">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2009.11069">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2009.11069">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>

                        <h3>2020</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.neurips.cc/paper_files/paper/2020/hash/ef9280fbc5317f17d480e4d4f61b3751-Abstract.html">Linearly converging error compensated SGD</a></span><span> (Eduard Gorbunov, Dmitry Kovalev, Dmitry Makarenko, Peter Richtárik). Advances in Neural Information Processing Systems, 2020.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.neurips.cc/paper_files/paper/2020/hash/ef9280fbc5317f17d480e4d4f61b3751-Abstract.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2010.12292">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2010.12292">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.neurips.cc/paper_files/paper/2020/hash/d530d454337fb09964237fecb4bea6ce-Abstract.html">Optimal and practical algorithms for smooth and strongly convex decentralized optimization</a></span><span> (Dmitry Kovalev, Adil Salim, Peter Richtárik). Advances in Neural Information Processing Systems, 2020.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.neurips.cc/paper_files/paper/2020/hash/d530d454337fb09964237fecb4bea6ce-Abstract.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2006.11773">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2006.11773">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.mlr.press/v117/kovalev20a.html">Don’t jump through hoops and remove those loops: SVRG and Katyusha are better without the outer loop</a></span><span> (Dmitry Kovalev, Samuel Horváth, Peter Richtárik). Algorithmic Learning Theory, 2020.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.mlr.press/v117/kovalev20a.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/1901.08689">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/1901.08689">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://link.springer.com/article/10.1134/S0965542520110020">Accelerated methods for saddle-point problem</a></span><span> (Mohammad S Alkousa, Alexander Vladimirovich Gasnikov, Darina Mikhailovna Dvinskikh, Dmitry A Kovalev, Fedor Sergeevich Stonyakin). Computational Mathematics and Mathematical Physics, 2020.<br/><div style="display:inline-block"><a class="paper-link" href="https://link.springer.com/article/10.1134/S0965542520110020">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/1906.03620">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/1906.03620">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="http://proceedings.mlr.press/v108/mishchenko20a">Revisiting stochastic extragradient</a></span><span> (Konstantin Mishchenko, Dmitry Kovalev, Egor Shulgin, Peter Richtárik, Yura Malitsky). International Conference on Artificial Intelligence and Statistics, 2020.<br/><div style="display:inline-block"><a class="paper-link" href="http://proceedings.mlr.press/v108/mishchenko20a">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/1905.11373">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/1905.11373">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.mlr.press/v119/li20g.html">Acceleration for compressed gradient descent in distributed and federated optimization</a></span><span> (Zhize Li, Dmitry Kovalev, Xun Qian, Peter Richtarik). International Conference on Machine Learning, 2020.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.mlr.press/v119/li20g.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2002.11364">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2002.11364">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="http://proceedings.mlr.press/v119/malinovskiy20a.html">From local SGD to local fixed-point methods for federated learning</a></span><span> (Grigory Malinovskiy, Dmitry Kovalev, Elnur Gasanov, Laurent Condat, Peter Richtarik). International Conference on Machine Learning, 2020.<br/><div style="display:inline-block"><a class="paper-link" href="http://proceedings.mlr.press/v119/malinovskiy20a.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2004.01442">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2004.01442">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.mlr.press/v119/hanzely20b.html">Variance reduced coordinate descent with acceleration: New method with a surprising application to finite-sum problems</a></span><span> (Filip Hanzely, Dmitry Kovalev, Peter Richtarik). International Conference on Machine Learning, 2020.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.mlr.press/v119/hanzely20b.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2002.04670">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2002.04670">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>

                        <h3>2019</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.neurips.cc/paper/2019/hash/bc6dc48b743dc5d013b1abaebd2faed2-Abstract.html">RSN: randomized subspace Newton</a></span><span> (Robert Gower, Dmitry Kovalev, Felix Lieder, Peter Richtárik). Advances in Neural Information Processing Systems, 2019.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.neurips.cc/paper/2019/hash/bc6dc48b743dc5d013b1abaebd2faed2-Abstract.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/1905.10874">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/1905.10874">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.neurips.cc/paper/2019/hash/6a8018b3a00b69c008601b8becae392b-Abstract.html">Stochastic proximal langevin algorithm: Potential splitting and nonasymptotic rates</a></span><span> (Adil Salim, Dmitry Kovalev, Peter Richtárik). Advances in Neural Information Processing Systems, 2019.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.neurips.cc/paper/2019/hash/6a8018b3a00b69c008601b8becae392b-Abstract.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/1905.11768">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/1905.11768">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>

                        <h3>2018</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="https://proceedings.neurips.cc/paper_files/paper/2018/hash/e721a54a8cf18c8543d44782d9ef681f-Abstract.html">Stochastic spectral and conjugate descent methods</a></span><span> (Dmitry Kovalev, Peter Richtárik, Eduard Gorbunov, Elnur Gasanov). Advances in Neural Information Processing Systems, 2018.<br/><div style="display:inline-block"><a class="paper-link" href="https://proceedings.neurips.cc/paper_files/paper/2018/hash/e721a54a8cf18c8543d44782d9ef681f-Abstract.html">Link<i class="fa fa-solid fa-link"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/1802.03703">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/1802.03703">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title"><a href="http://crm-en.ics.org.ru/journal/article/2685/">A hypothesis about the rate of global convergence for optimal methods (Newton’s type) in smooth convex optimization</a></span><span> (Alexander Gasnikov, Dmitry Kovalev). Computer research and modeling, 2018.<br/><div style="display:inline-block"><a class="paper-link" href="http://crm-en.ics.org.ru/journal/article/2685/">Link<i class="fa fa-solid fa-link"></i></a></div></span></div>

                    </div>
                </div>
            </div>
        </div>
    </section>
    <section id="preprints">
        <div class="div-section div-section-dark">
            <div class="container">
                <div class="row">
                    <div class="col-lg-4">
                        <h1 class="h-section">Preprints</h1>
                    </div>
                    <div class="col">
                        <h3>2024</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title">On Linear Convergence in Smooth Convex-Concave Bilinearly-Coupled Saddle-Point Optimization: Lower Bounds and Optimal Algorithms</span><span> (Dmitry Kovalev, Ekaterina Borodich). arXiv preprint arXiv:2411.14601, 2024.<br/><div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2411.14601">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2411.14601">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title">Decentralized Optimization with Coupled Constraints</span><span> (Demyan Yarmoshik, Alexander Rogozin, Nikita Kiselev, Daniil Dorin, Alexander Gasnikov, Dmitry Kovalev). arXiv preprint arXiv:2407.02020, 2024.<br/><div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2407.02020">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2407.02020">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title">Lower Bounds and Optimal Algorithms for Non-Smooth Convex Decentralized Optimization over Time-Varying Networks</span><span> (Dmitry Kovalev, Ekaterina Borodich, Alexander Gasnikov, Dmitrii Feoktistov). arXiv preprint arXiv:2405.18031, 2024.<br/><div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2405.18031">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2405.18031">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title">Decentralized finite-sum optimization over time-varying networks</span><span> (Dmitry Metelev, Savelii Chezhegov, Alexander Rogozin, Aleksandr Beznosikov, Alexander Sholokhov, Alexander Gasnikov, Dmitry Kovalev). arXiv preprint arXiv:2402.02490, 2024.<br/><div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2402.02490">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2402.02490">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>

                        <h3>2023</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title">Optimal algorithm with complexity separation for strongly convex-strongly concave composite saddle point problems</span><span> (Ekaterina Borodich, Georgiy Kormakov, Dmitry Kovalev, Aleksandr Beznosikov, Alexander Gasnikov). arXiv preprint arXiv:2307.12946, 2023.<br/><div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2307.12946">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2307.12946">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>

                        <h3>2022</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title">An optimal algorithm for strongly convex min-min optimization</span><span> (Alexander Gasnikov, Dmitry Kovalev, Grigory Malinovsky). arXiv preprint arXiv:2212.14439, 2022.<br/><div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2212.14439">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2212.14439">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title">On scaled methods for saddle point problems</span><span> (Aleksandr Beznosikov, Aibek Alanov, Dmitry Kovalev, Martin Takáč, Alexander Gasnikov). arXiv preprint arXiv:2206.08303, 2022.<br/><div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2206.08303">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2206.08303">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>

                        <h3>2021</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title">Decentralized distributed optimization for saddle point problems</span><span> (Alexander Rogozin, Aleksandr Beznosikov, Darina Dvinskikh, Dmitry Kovalev, Pavel Dvurechensky, Alexander Gasnikov). arXiv preprint arXiv:2102.07758, 2021.<br/><div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2102.07758">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2102.07758">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>

                        <h3>2020</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title">Fast linear convergence of randomized BFGS</span><span> (Dmitry Kovalev, Robert M Gower, Peter Richtárik, Alexander Rogozin). arXiv preprint arXiv:2002.11337, 2020.<br/><div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/2002.11337">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/2002.11337">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>

                        <h3>2019</h3>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title">Distributed fixed point methods with compressed iterates</span><span> (Sélim Chraibi, Ahmed Khaled, Dmitry Kovalev, Peter Richtárik, Adil Salim, Martin Takáč). arXiv preprint arXiv:1912.09925, 2019.<br/><div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/1912.09925">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/1912.09925">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>
                        <div class="div-publication"><svg xmlns="http://www.w3.org/2000/svg" viewBox="-64 0 512 512" width="1em" height="1em" fill="currentColor">
                                <!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc. -->
                                <path d="M64 464c-8.8 0-16-7.2-16-16V64c0-8.8 7.2-16 16-16H224v80c0 17.7 14.3 32 32 32h80V448c0 8.8-7.2 16-16 16H64zM64 0C28.7 0 0 28.7 0 64V448c0 35.3 28.7 64 64 64H320c35.3 0 64-28.7 64-64V154.5c0-17-6.7-33.3-18.7-45.3L274.7 18.7C262.7 6.7 246.5 0 229.5 0H64zm56 256c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120zm0 96c-13.3 0-24 10.7-24 24s10.7 24 24 24H264c13.3 0 24-10.7 24-24s-10.7-24-24-24H120z"></path>
                            </svg>&nbsp;<span class="span-paper-title">Stochastic Newton and cubic Newton methods with simple local linear-quadratic rates</span><span> (Dmitry Kovalev, Konstantin Mishchenko, Peter Richtárik). arXiv preprint arXiv:1912.01597, 2019.<br/><div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/abs/1912.01597">arXiv<i class="ai ai-arxiv"></i></a></div> <div style="display:inline-block"><a class="paper-link" href="https://arxiv.org/pdf/1912.01597">PDF<i class="fa fa-regular fa-file-pdf"></i></a></div></span></div>

                    </div>
                </div>
            </div>
        </div>
    </section>
    <section id="contact">
        <div class="div-section">
            <div class="container">
                <div class="row">
                    <div class="col-lg-4">
                        <h1 class="h-section">Contact</h1>
                    </div>
                    <div class="col">
                        <div class="div-contact">
                            <div class="row">
                                <div class="col-auto align-self-center"><i class="fa fa-envelope i-contact"></i></div>
                                <div class="col align-self-center"><a href="mailto:dakovalev1@gmail.com">dakovalev1@gmail.com</a></div>
                            </div>
                            <div class="row">
                                <div class="col-auto align-self-center"><i class="fa fa-phone i-contact"></i></div>
                                <div class="col align-self-center"><a href="tel:+79057190698">+7 905 719 06 98</a></div>
                            </div>
                            <div class="row">
                                <div class="col-auto align-self-center"><i class="fa fa-map-marker i-contact"></i></div>
                                <div class="col align-self-center"><span>Morozov Business Center, Room 2474<br>Moscow, 119021, Russia</span></div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/bootstrap/js/bootstrap.min.js"></script>
    <script src="assets/js/main.js"></script>
</body>

</html>