{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import bs4\n",
    "import pickle\n",
    "import urllib.parse\n",
    "import textwrap\n",
    "import dateparser\n",
    "import jinja2\n",
    "import datetime\n",
    "import unidecode\n",
    "\n",
    "\n",
    "PROXY_URL = \"http://5zipXAuZVPsquwtL:wifi;;;;@proxy.froxy.com:9000\"\n",
    "SCHOLAR_PROFILE = \"qHFA5z4AAAAJ\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Title', 'Authors', 'Publication date', 'Journal', 'Volume', 'Issue', 'Pages', 'Publisher', 'Description', 'Total citations', 'Scholar articles', 'Version urls'])\n"
     ]
    }
   ],
   "source": [
    "paper_dict_list: typing.List[typing.Dict[str, bs4.Tag]] = pickle.load(\n",
    "    open(\"paper_urls.txt\", \"rb\")\n",
    ")\n",
    "print(paper_dict_list[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBLISHER_NETLOC = set(\n",
    "    [\n",
    "        \"proceedings.neurips.cc\",\n",
    "        \"proceedings.mlr.press\",\n",
    "        \"link.springer.com\",\n",
    "        \"ems.press\",\n",
    "        \"www.sciencedirect.com\",\n",
    "        \"www.tandfonline.com\",\n",
    "        \"crm-en.ics.org.ru\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class Paper:\n",
    "    def __init__(self, paper_dict: typing.Dict[str, bs4.Tag]) -> None:\n",
    "        self.title: str = paper_dict[\"Title\"].text\n",
    "        self.authors: str = paper_dict[\"Authors\"].text\n",
    "        self.year: int = dateparser.parse(paper_dict[\"Publication date\"].text).year\n",
    "\n",
    "        self.venue: str = \"\"\n",
    "        self.type: str = \"\"\n",
    "\n",
    "        if \"Journal\" in paper_dict.keys():\n",
    "            self.venue = paper_dict[\"Journal\"].text\n",
    "            if self.venue.lower().startswith(\"arxiv\"):\n",
    "                self.type = \"preprint\"\n",
    "            else:\n",
    "                self.type = \"publication\"\n",
    "        elif \"Conference\" in paper_dict.keys():\n",
    "            self.venue = paper_dict[\"Conference\"].text\n",
    "            self.type = \"publication\"\n",
    "        elif \"Book\" in paper_dict.keys():\n",
    "            self.venue = paper_dict[\"Book\"].text\n",
    "            self.type = \"publication\"\n",
    "        elif \"Institution\" in paper_dict.keys():\n",
    "            self.venue = paper_dict[\"Institution\"].text\n",
    "            self.type = \"thesis\"\n",
    "        else:\n",
    "            raise KeyError(\"unknown paper type\")\n",
    "\n",
    "        self.link: str | None = None\n",
    "        self.openreview: str | None = None\n",
    "        self.arxiv: str | None = None\n",
    "        self.pdf: str | None = None\n",
    "\n",
    "        for url in paper_dict[\"Version urls\"]:\n",
    "            url_parsed: urllib.parse.ParseResult = urllib.parse.urlparse(url)\n",
    "            if self.arxiv is None and url_parsed.netloc == \"arxiv.org\":\n",
    "                self.arxiv = url\n",
    "            if self.openreview is None and url_parsed.netloc == \"openreview.net\":\n",
    "                self.openreview = url\n",
    "            if self.link is None and url_parsed.netloc in PUBLISHER_NETLOC:\n",
    "                self.link = url\n",
    "            if self.pdf is None and url_parsed.path.lower().endswith(\"pdf\"):\n",
    "                self.pdf = url\n",
    "\n",
    "        if self.type == \"preprint\":\n",
    "            self.link = self.arxiv\n",
    "\n",
    "        if not self.arxiv is None:\n",
    "            self.pdf = self.arxiv.replace(\"abs\", \"pdf\")\n",
    "\n",
    "        print(self.title)\n",
    "        for url in paper_dict[\"Version urls\"]:\n",
    "            print(\"\\t\", url)\n",
    "\n",
    "    def to_html(self) -> str:\n",
    "        span_title = bs4.Tag(name=\"span\", attrs={\"class\": \"span-paper-title\"})\n",
    "\n",
    "        if self.link is None:\n",
    "            span_title.append(self.title)\n",
    "        else:\n",
    "            a_title = bs4.Tag(name=\"a\", attrs={\"href\": self.link})\n",
    "            a_title.append(self.title)\n",
    "            span_title.append(a_title)\n",
    "\n",
    "        span = bs4.Tag(name=\"span\")\n",
    "        span.append(f\" ({self.authors}). {self.venue}, {self.year}.\")\n",
    "\n",
    "        links: typing.List[str] = []\n",
    "\n",
    "        if not self.link is None:\n",
    "            a_link = bs4.Tag(name=\"a\", attrs={\"href\": self.link})\n",
    "            a_link.append(\"Link\")\n",
    "            links.append(str(a_link))\n",
    "\n",
    "        # if self.type == \"publication\" and not self.openreview is None:\n",
    "        #     a_openreview = bs4.Tag(name=\"a\", attrs={\"href\": self.openreview})\n",
    "        #     a_openreview.append(\"OpenReview\")\n",
    "        #     links.append(str(a_openreview))\n",
    "\n",
    "        if self.type != \"preprint\" and not self.arxiv is None:\n",
    "            a_arxiv = bs4.Tag(name=\"a\", attrs={\"href\": self.arxiv})\n",
    "            a_arxiv.append(\"arXiv\")\n",
    "            links.append(str(a_arxiv))\n",
    "\n",
    "        if not self.pdf is None:\n",
    "            a_pdf = bs4.Tag(name=\"a\", attrs={\"href\": self.pdf})\n",
    "            a_pdf.append(\"PDF\")\n",
    "            links.append(str(a_pdf))\n",
    "\n",
    "        if len(links):\n",
    "            span.append(\" [\")\n",
    "            span.append(bs4.BeautifulSoup(\", \".join(links), \"html.parser\"))\n",
    "            span.append(\"].\")\n",
    "\n",
    "        soup = bs4.BeautifulSoup()\n",
    "        soup.append(span_title)\n",
    "        soup.append(span)\n",
    "\n",
    "        print(soup, links)\n",
    "        return soup\n",
    "\n",
    "    def to_latex(self) -> str:\n",
    "        latex: str = \"\"\n",
    "\n",
    "        if self.link is None:\n",
    "            latex += f\"\\\\textbf{{{self.title}}}\"\n",
    "        else:\n",
    "            latex += f\"\\\\textbf{{\\\\href{{{self.link}}}{{{self.title}}}}}\"\n",
    "\n",
    "        latex += f\" ({unidecode.unidecode(self.authors)}). \\\\textit{{{self.venue}}}, {self.year}.\"\n",
    "        return latex\n",
    "\n",
    "    def __lt__(self, other: typing.Self) -> bool:\n",
    "        return (\n",
    "            self.year > other.year\n",
    "            or (self.year == other.year and self.venue < other.venue)\n",
    "            or (\n",
    "                self.year == other.year\n",
    "                and self.venue == other.venue\n",
    "                and self.title < other.title\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return '<Paper title=\"{}\" authors=\"{}\" venue=\"{}\" year = {}>'.format(\n",
    "            textwrap.shorten(self.title, width=30, placeholder=\"...\"),\n",
    "            textwrap.shorten(self.authors, width=30, placeholder=\"...\"),\n",
    "            self.venue,\n",
    "            self.year,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stochastic distributed learning with gradient quantization and double-variance reduction\n",
      "\t https://www.tandfonline.com/doi/abs/10.1080/10556788.2022.2117355\n",
      "\t https://repository.kaust.edu.sa/bitstream/10754/653103/1/1904.05115.pdf\n",
      "\t https://dclibrary.mbzuai.ac.ae/mlfp/359/\n",
      "\t https://arxiv.org/abs/1904.05115\n",
      "\t https://www.researchgate.net/profile/Samuel-Horvath-2/publication/332342206_Stochastic_Distributed_Learning_with_Gradient_Quantization_and_Variance_Reduction/links/5d359e724585153e5916c157/Stochastic-Distributed-Learning-with-Gradient-Quantization-and-Variance-Reduction.pdf\n",
      "\t https://ui.adsabs.harvard.edu/abs/2019arXiv190405115H/abstract\n",
      "\t https://2019.ds3-datascience-polytechnique.fr/wp-content/uploads/2019/06/DS3-608_2019.pdf\n",
      "\t https://publications.cispa.saarland/id/eprint/3980\n",
      "\t https://www.ds3-datascience-polytechnique.fr/wp-content/uploads/2019/06/DS3-608_2019.pdf\n",
      "\t https://nchr.elsevierpure.com/en/publications/stochastic-distributed-learning-with-gradient-quantization-and-do\n",
      "\t https://core.ac.uk/download/pdf/599569336.pdf\n",
      "\t https://www.ingentaconnect.com/content/tandf/goms/2023/00000038/00000001/art00004\n",
      "\t https://publications.cispa.de/articles/journal_contribution/Stochastic_distributed_learning_with_gradient_quantization_and_double-variance_reduction/25469572\n",
      "\t https://infoscience.epfl.ch/record/297436\n",
      "\t https://publications.cispa.de/ndownloader/files/45257332\n",
      "\t https://repository.kaust.edu.sa/items/e8e43ddb-362d-415c-9815-95432bbcb200\n",
      "\t https://publications.cispa.saarland/3980/\n",
      "Don’t jump through hoops and remove those loops: SVRG and Katyusha are better without the outer loop\n",
      "\t https://proceedings.mlr.press/v117/kovalev20a.html\n",
      "\t https://ui.adsabs.harvard.edu/abs/2019arXiv190108689K/abstract\n",
      "\t https://repository.kaust.edu.sa/handle/10754/653122\n",
      "\t https://arxiv.org/abs/1901.08689\n",
      "\t http://proceedings.mlr.press/v117/kovalev20a.html\n",
      "\t http://dml.mathdoc.fr/item/1901.08689/\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/cad85c90-bfce-430d-ad1a-f74af61a3f4c/content\n",
      "Acceleration for compressed gradient descent in distributed and federated optimization\n",
      "\t https://arxiv.org/abs/2002.11364\n",
      "\t https://repository.kaust.edu.sa/bitstreams/219e1c40-7bf6-42e0-b059-4c71112b7b66/download\n",
      "\t https://www.researchgate.net/profile/Zhize-Li/publication/339526946_Acceleration_for_Compressed_Gradient_Descent_in_Distributed_and_Federated_Optimization/links/5e59fe2b4585152ce8f85f96/Acceleration-for-Compressed-Gradient-Descent-in-Distributed-and-Federated-Optimization.pdf\n",
      "\t https://ui.adsabs.harvard.edu/abs/2020arXiv200211364L/abstract\n",
      "\t https://icml.cc/media/Slides/icml/2020/virtual(no-parent)-15-19-00UTC-6191-acceleration_fo.pdf\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3524938.3525485\n",
      "\t https://ink.library.smu.edu.sg/sis_research/8681/\n",
      "\t https://zhizeli.github.io/files/acgd_slides.pdf\n",
      "\t https://pdfs.semanticscholar.org/bd68/6257ad1f948a30a37c32f91abb388ce62e1e.pdf\n",
      "\t https://elibrary.ru/item.asp?id=45863264\n",
      "\t https://proceedings.mlr.press/v119/li20g.html\n",
      "\t https://icml.cc/media/icml-2020/Slides/6191.pdf\n",
      "\t http://proceedings.mlr.press/v119/li20g.html\n",
      "\t https://repository.kaust.edu.sa/handle/10754/662100\n",
      "\t https://ink.library.smu.edu.sg/cgi/viewcontent.cgi?params=/context/sis_research/article/9684/&path_info=ICML20_full_adiana.pdf\n",
      "From local SGD to local fixed-point methods for federated learning\n",
      "\t http://proceedings.mlr.press/v119/malinovskiy20a.html\n",
      "\t https://elibrary.ru/item.asp?id=46742951\n",
      "\t https://repository.kaust.edu.sa/handle/10754/662492\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3524938.3525559\n",
      "\t https://ui.adsabs.harvard.edu/abs/2020arXiv200401442M/abstract\n",
      "\t http://proceedings.mlr.press/v119/malinovskiy20a/malinovskiy20a-supp.pdf\n",
      "\t https://arxiv.org/abs/2004.01442\n",
      "\t https://www.researchgate.net/profile/Grigory-Malinovskiy/publication/340452734_From_Local_SGD_to_Local_Fixed_Point_Methods_for_Federated_Learning/links/5f0974b145851550509c7be9/From-Local-SGD-to-Local-Fixed-Point-Methods-for-Federated-Learning.pdf\n",
      "\t https://repository.kaust.edu.sa/bitstreams/a75121f4-6d92-4f67-8044-762506afe24b/download\n",
      "RSN: randomized subspace Newton\n",
      "\t https://proceedings.neurips.cc/paper/2019/hash/bc6dc48b743dc5d013b1abaebd2faed2-Abstract.html\n",
      "\t https://arxiv.org/abs/1905.10874\n",
      "\t https://richtarik.org/posters/Poster-RSN.pdf\n",
      "\t https://telecom-paris.hal.science/hal-02365297/\n",
      "\t https://elibrary.ru/item.asp?id=45384452\n",
      "\t http://papers.neurips.cc/paper/8351-rsn-randomized-subspace-newton.pdf\n",
      "\t https://openreview.net/forum?id=ByfmEEreIS\n",
      "\t https://gowerrobert.github.io/pdf/posters/RSN_neurips_poster.pdf\n",
      "\t https://repository.kaust.edu.sa/items/a520cf0c-eb52-4a2a-a786-59de82dc4ec5\n",
      "\t https://ui.adsabs.harvard.edu/abs/2019arXiv190510874G/abstract\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2019/hash/bc6dc48b743dc5d013b1abaebd2faed2-Abstract.html\n",
      "\t https://hal.science/hal-02365297/\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3454287.3454343\n",
      "\t https://repository.kaust.edu.sa/handle/10754/660275\n",
      "Linearly converging error compensated SGD\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2020/hash/ef9280fbc5317f17d480e4d4f61b3751-Abstract.html\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3495724.3497478\n",
      "\t https://pdfs.semanticscholar.org/a6d2/462e8b1777a896058b184923f9129c63a794.pdf\n",
      "\t https://arxiv.org/abs/2010.12292\n",
      "\t https://elibrary.ru/item.asp?id=46790933\n",
      "\t https://www.researchgate.net/profile/Eduard-Gorbunov/publication/344878095_Linearly_Converging_Error_Compensated_SGD/links/61f2bd369a753545e2fe8a69/Linearly-Converging-Error-Compensated-SGD.pdf\n",
      "\t https://proceedings.neurips.cc/paper/2020/hash/ef9280fbc5317f17d480e4d4f61b3751-Abstract.html\n",
      "\t https://repository.kaust.edu.sa/handle/10754/666025\n",
      "\t https://ui.adsabs.harvard.edu/abs/2020arXiv201012292G/abstract\n",
      "\t https://openreview.net/forum?id=t6y7IjScg2m\n",
      "\t https://eduardgorbunov.github.io/assets/files/neurips_after_party_2021.pdf\n",
      "\t https://eduardgorbunov.github.io/assets/files/ef_sigma_k_poster.pdf\n",
      "Revisiting stochastic extragradient\n",
      "\t http://proceedings.mlr.press/v108/mishchenko20a\n",
      "\t https://repository.kaust.edu.sa/bitstream/handle/10754/660278/Preprintfile1.pdf?sequence=1\n",
      "\t https://ui.adsabs.harvard.edu/abs/2019arXiv190511373M/abstract\n",
      "\t https://www.academia.edu/download/82489114/1905.11373.pdf\n",
      "\t https://www.konstmish.com/uploads/slides/20-extra.pdf\n",
      "\t http://proceedings.mlr.press/v108/mishchenko20a.html\n",
      "\t https://arxiv.org/abs/1905.11373\n",
      "\t https://repository.kaust.edu.sa/items/38d0a1b0-e999-4edb-8fd7-fb95f0d487e7\n",
      "Optimal and practical algorithms for smooth and strongly convex decentralized optimization\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2020/hash/d530d454337fb09964237fecb4bea6ce-Abstract.html\n",
      "\t https://proceedings.neurips.cc/paper/2020/hash/d530d454337fb09964237fecb4bea6ce-Abstract.html\n",
      "\t https://repository.kaust.edu.sa/bitstreams/45db2111-7c3c-4002-bf35-72ccc792492e/download\n",
      "\t https://arxiv.org/abs/2006.11773\n",
      "\t https://ui.adsabs.harvard.edu/abs/2020arXiv200611773K/abstract\n",
      "\t https://papers.neurips.cc/paper_files/paper/2020/file/d530d454337fb09964237fecb4bea6ce-Paper.pdf\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3495724.3497264\n",
      "\t https://repository.kaust.edu.sa/handle/10754/666022\n",
      "A linearly convergent algorithm for decentralized optimization: Sending less bits for free!\n",
      "\t https://proceedings.mlr.press/v130/kovalev21a.html\n",
      "\t http://proceedings.mlr.press/v130/kovalev21a\n",
      "\t https://arxiv.org/abs/2011.01697\n",
      "\t https://infoscience.epfl.ch/record/286864\n",
      "\t https://richtarik.org/posters/Poster-Decentralized-DIANA.pdf\n",
      "\t https://ui.adsabs.harvard.edu/abs/2020arXiv201101697K/abstract\n",
      "\t https://repository.kaust.edu.sa/handle/10754/665879\n",
      "\t https://repository.kaust.edu.sa/bitstreams/e5c7d805-a861-4dc8-a17f-cf7d6e58d3d2/download\n",
      "\t https://infoscience.epfl.ch/record/286864?v=pdf\n",
      "Accelerated methods for saddle-point problem\n",
      "\t https://link.springer.com/article/10.1134/S0965542520110020\n",
      "\t https://repository.kaust.edu.sa/handle/10754/666346\n",
      "\t https://search.ebscohost.com/login.aspx?direct=true&profile=ehost&scope=site&authtype=crawler&jrnl=09655425&AN=147479258&h=DqWtxV31KzxKDWR3KUGun43VDY8bDJ%2Bz9%2FS95X7SVsRR8f7JJybjHTMlbrRaetihd%2BenJ8EVa0B6Vx0EnF63Ow%3D%3D&crl=c\n",
      "\t https://www.mathnet.ru/eng/zvmmf11157\n",
      "\t https://ui.adsabs.harvard.edu/abs/2020CMMPh..60.1787A/abstract\n",
      "\t https://elibrary.ru/item.asp?id=45099936\n",
      "\t https://www.mathnet.ru/eng/zvmmf/v60/i11/p1843\n",
      "\t https://arxiv.org/abs/1906.03620\n",
      "\t https://ui.adsabs.harvard.edu/abs/2019arXiv190603620A/abstract\n",
      "Stochastic Newton and cubic Newton methods with simple local linear-quadratic rates\n",
      "\t https://arxiv.org/abs/1912.01597\n",
      "\t https://repository.kaust.edu.sa/handle/10754/660727\n",
      "\t https://ui.adsabs.harvard.edu/abs/2019arXiv191201597K/abstract\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/766f5e70-bb84-4c1b-81ad-efd9c3aaa6b3/content\n",
      "Decentralized distributed optimization for saddle point problems\n",
      "\t https://arxiv.org/abs/2102.07758\n",
      "\t https://repository.kaust.edu.sa/handle/10754/667615\n",
      "\t https://ui.adsabs.harvard.edu/abs/2021arXiv210207758R/abstract\n",
      "\t https://www.researchgate.net/profile/Pavel-Dvurechensky/publication/349335061_Decentralized_Distributed_Optimization_for_Saddle_Point_Problems/links/6076cc65a03fca55fe29919e/Decentralized-Distributed-Optimization-for-Saddle-Point-Problems.pdf\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/ff50fd83-96e5-4515-bd72-0ea1472bb07f/content\n",
      "Lower bounds and optimal algorithms for smooth and strongly convex decentralized optimization over time-varying networks\n",
      "\t https://proceedings.neurips.cc/paper/2021/hash/bc37e109d92bdc1ea71da6c919d54907-Abstract.html\n",
      "\t https://proceedings.neurips.cc/paper/2021/hash/bc37e109d92bdc1ea71da6c919d54907-Abstract.html?roistat_visit=7938444\n",
      "\t https://labmmo.ru/upload/000/u8/3/8/2106-04469.pdf\n",
      "\t https://arxiv.org/abs/2106.04469\n",
      "\t https://papers.neurips.cc/paper/2021/file/bc37e109d92bdc1ea71da6c919d54907-Paper.pdf\n",
      "\t https://fl-icml.github.io/2021/papers/FL-ICML21_paper_46.pdf\n",
      "\t https://ui.adsabs.harvard.edu/abs/2021arXiv210604469K/abstract\n",
      "\t https://proceedings.nips.cc/paper/2021/file/bc37e109d92bdc1ea71da6c919d54907-Paper.pdf\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3540261.3541971\n",
      "\t https://elibrary.ru/item.asp?id=49123379\n",
      "\t https://openreview.net/forum?id=L8-54wkift\n",
      "\t https://repository.kaust.edu.sa/handle/10754/669593.1\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/239fe39a-dabf-4148-a5bf-fdc56ef785b1/content\n",
      "Accelerated primal-dual gradient method for smooth and convex-concave saddle-point problems with bilinear coupling\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2022/hash/883f66687a521536c505f9b2fbdcbf1e-Abstract-Conference.html\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2022/file/883f66687a521536c505f9b2fbdcbf1e-Supplemental-Conference.pdf\n",
      "\t https://arxiv.org/abs/2112.15199\n",
      "\t https://repository.kaust.edu.sa/handle/10754/692832\n",
      "\t https://labmmo.ru/upload/000/u8/6/f/2112-15199.pdf\n",
      "\t https://openreview.net/forum?id=FncDhRcRYiN\n",
      "\t https://ui.adsabs.harvard.edu/abs/2021arXiv211215199K/abstract\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3600270.3601849\n",
      "ADOM: accelerated decentralized optimization method for time-varying networks\n",
      "\t http://proceedings.mlr.press/v139/kovalev21a\n",
      "\t https://shulgin-egor.github.io/files/adom_poster.pdf\n",
      "\t https://richtarik.org/posters/Poster-ADOM-ICML-2021.pdf\n",
      "\t http://proceedings.mlr.press/v139/kovalev21a/kovalev21a-supp.pdf\n",
      "\t https://arxiv.org/abs/2102.09234\n",
      "\t https://ui.adsabs.harvard.edu/abs/2021arXiv210209234K/abstract\n",
      "\t https://labmmo.ru/upload/000/u8/c/2/2102-09234.pdf\n",
      "\t https://repository.kaust.edu.sa/bitstreams/d0a7e842-7669-49ac-9ada-ae82ce9280f5/download\n",
      "\t https://icml.cc/media/icml-2021/Slides/10125.pdf\n",
      "\t https://repository.kaust.edu.sa/handle/10754/667661\n",
      "\t https://shulgin-egor.github.io/publication/adom/adom_poster.pdf\n",
      "Optimal algorithms for decentralized stochastic variational inequalities\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2022/hash/c959bb2cb164d37569a17fa67494d69a-Abstract-Conference.html\n",
      "\t https://ui.adsabs.harvard.edu/abs/2022arXiv220202771K/abstract\n",
      "\t https://arxiv.org/abs/2202.02771\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3600270.3602523\n",
      "\t https://repository.kaust.edu.sa/handle/10754/677972\n",
      "\t https://openreview.net/forum?id=omI5hgwgrsa\n",
      "\t https://labmmo.ru/upload/000/u8/2/2/2202-02771.pdf\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/b402bccc-272c-4cfb-acb5-1cb3a2d745f0/content\n",
      "Accelerated variance-reduced methods for saddle-point problems\n",
      "\t https://arxiv.org/abs/2103.09344\n",
      "\t https://ui.adsabs.harvard.edu/abs/2021arXiv210309344T/abstract\n",
      "\t https://www.academia.edu/download/96798398/2103.09344v2.pdf\n",
      "\t https://labmmo.ru/upload/000/u8/b/a/2103-09344.pdf\n",
      "\t https://www.mathnet.ru/eng/crm1069\n",
      "\t http://crm.ics.org.ru/uploads/crmissues/crm_2023_02/22_tominin.pdf\n",
      "\t https://labmmo.ru/upload/000/u8/1/9/22-tominin.pdf\n",
      "\t http://www.crm.ics.org.ru/uploads/crmissues/crm_2023_02/22_tominin.pdf\n",
      "\t http://vst.ics.org.ru/uploads/crmissues/crm_2023_02/22_tominin.pdf\n",
      "\t http://crm-en.ics.org.ru/uploads/crmissues/crm_2023_02/22_tominin.pdf\n",
      "\t http://crm-en.ics.org.ru/journal/article/3325/\n",
      "\t https://www.sciencedirect.com/science/article/pii/S2192440622000247\n",
      "\t https://labmmo.ru/upload/000/u8/6/3/1-s2-0-s2192440622000247-main.pdf\n",
      "\t https://repository.kaust.edu.sa/bitstream/10754/685261/1/1-s2.0-S2192440622000247-main.pdf\n",
      "\t https://oa.tib.eu/renate/handle/123456789/11625\n",
      "\t https://scholar.archive.org/work/sykq2i3kyfcw3gkvw3u5f7grvq/access/wayback/https://oa.tib.eu/renate/bitstream/123456789/11625/1/1-s2-0-S2192440622000247-main.pdf\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/94f2de67-b691-4460-a94d-208468c92094/content\n",
      "\t https://oa.tib.eu/renate/backend/api/core/bitstreams/893b3e1f-6e0d-4f5b-8f84-05e137a58338/content\n",
      "\t https://repository.kaust.edu.sa/handle/10754/693497\n",
      "\t https://repository.kaust.edu.sa/items/37b99088-d0fb-4ab9-a25e-31eb3e84198d\n",
      "The first optimal acceleration of high-order methods in smooth convex optimization\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2022/hash/e56f394bbd4f0ec81393d767caa5a31b-Abstract-Conference.html\n",
      "\t https://ui.adsabs.harvard.edu/abs/2022arXiv220509647K/abstract\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2022/file/e56f394bbd4f0ec81393d767caa5a31b-Supplemental-Conference.pdf\n",
      "\t https://repository.kaust.edu.sa/handle/10754/678185\n",
      "\t https://openreview.net/forum?id=YgmiL2Ur01P\n",
      "\t https://papers.neurips.cc/paper_files/paper/2022/file/e56f394bbd4f0ec81393d767caa5a31b-Supplemental-Conference.pdf\n",
      "\t https://arxiv.org/abs/2205.09647\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3600270.3602831\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/b4044a21-effb-419e-83f8-9c6fa796386b/content\n",
      "\t https://papers.neurips.cc/paper_files/paper/2022/file/e56f394bbd4f0ec81393d767caa5a31b-Paper-Conference.pdf\n",
      "Towards accelerated rates for distributed optimization over time-varying networks\n",
      "\t https://link.springer.com/chapter/10.1007/978-3-030-91059-4_19\n",
      "\t https://labmmo.ru/upload/000/u8/e/b/2009-11069.pdf\n",
      "\t https://arxiv.org/abs/2009.11069\n",
      "\t https://dl.acm.org/doi/abs/10.1007/978-3-030-91059-4_19\n",
      "\t https://link.springer.com/content/pdf/10.1007/978-3-030-91059-4.pdf#page=272\n",
      "\t https://repository.kaust.edu.sa/handle/10754/665439\n",
      "\t https://ui.adsabs.harvard.edu/abs/2020arXiv200911069R/abstract\n",
      "\t https://books.google.com/books?hl=en&lr=&id=6HlMEAAAQBAJ&oi=fnd&pg=PA258&ots=aRod_JtBSn&sig=80W5wwG_uN9qqR6v85fypndK55g\n",
      "\t https://elibrary.ru/item.asp?id=47535257\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/11f0c1f2-6dd2-4526-a2cf-0c9e047a3a16/content\n",
      "Stochastic proximal langevin algorithm: Potential splitting and nonasymptotic rates\n",
      "\t https://proceedings.neurips.cc/paper/2019/hash/6a8018b3a00b69c008601b8becae392b-Abstract.html\n",
      "\t https://openreview.net/forum?id=HklDsNrlIr\n",
      "\t https://ui.adsabs.harvard.edu/abs/2019arXiv190511768S/abstract\n",
      "\t https://elibrary.ru/item.asp?id=45347186\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3454287.3454884\n",
      "\t https://adil-salim.github.io/Research/langevin19.pdf\n",
      "\t https://arxiv.org/abs/1905.11768\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2019/hash/6a8018b3a00b69c008601b8becae392b-Abstract.html\n",
      "\t https://richtarik.org/posters/Poster-SPLA.pdf\n",
      "\t https://repository.kaust.edu.sa/bitstream/handle/10754/660280/Preprintfile1.pdf?sequence=1\n",
      "\t http://papers.neurips.cc/paper/8891-stochastic-proximal-langevin-algorithm-potential-splitting-and-nonasymptotic-rates.pdf\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/370aa404-7758-4366-b92f-f73bc2147526/content\n",
      "\t https://adil-salim.github.io/Research/poster-langevin19.pdf\n",
      "IntSGD: Adaptive floatless compression of stochastic gradients\n",
      "\t https://arxiv.org/abs/2102.08374\n",
      "\t https://repository.kaust.edu.sa/handle/10754/667733\n",
      "\t https://www.datascienceassn.org/sites/default/files/IntSGD%20Floatless%20Compression%20of%20Stochastic%20Gradients.pdf\n",
      "\t https://ui.adsabs.harvard.edu/abs/2021arXiv210208374M/abstract\n",
      "\t https://www.konstmish.com/uploads/slides/22-intsgd-slides.pdf\n",
      "\t https://openreview.net/forum?id=pFyXqxChZc\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/5849784f-31de-480c-a3ed-a80e47f2d376/content\n",
      "\t https://repository.kaust.edu.sa/bitstreams/c2660e1d-6c39-4815-8bfe-71587f858327/download\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/c2660e1d-6c39-4815-8bfe-71587f858327/content\n",
      "An optimal algorithm for strongly convex minimization under affine constraints\n",
      "\t https://proceedings.mlr.press/v151/salim22a.html\n",
      "\t https://arxiv.org/abs/2102.11079\n",
      "\t https://repository.kaust.edu.sa/handle/10754/667732\n",
      "\t https://lcondat.github.io/publis/Salim_AISTATS_2022.pdf\n",
      "\t https://ui.adsabs.harvard.edu/abs/2021arXiv210211079S/abstract\n",
      "\t https://repository.kaust.edu.sa/bitstreams/d4e147fb-6317-4dfc-ba50-33777751bda0/download\n",
      "Distributed fixed point methods with compressed iterates\n",
      "\t https://arxiv.org/abs/1912.09925\n",
      "\t https://ui.adsabs.harvard.edu/abs/2019arXiv191209925C/abstract\n",
      "\t https://richtarik.org/papers/DFPMCI-new.pdf\n",
      "\t https://richtarik.org/papers/FPMCI.pdf\n",
      "Smooth monotone stochastic variational inequalities and saddle point problems: A survey\n",
      "\t https://ems.press/journals/mag/articles/9939904\n",
      "\t https://content.ems.press/assets/public/full-texts/serials/mag/127/9939904/online/10.4171-mag-112.pdf\n",
      "\t https://arxiv.org/abs/2208.13592\n",
      "\t https://ui.adsabs.harvard.edu/abs/2022arXiv220813592B/abstract\n",
      "\t https://euromathsoc.org/magazine/articles/112\n",
      "\t https://repository.kaust.edu.sa/handle/10754/680934\n",
      "\t https://ems.press/content/serial-article-files/27019\n",
      "\t https://content.ems.press/assets/public/full-texts/serials/mag/127/9939904/online-first/10.4171-mag-112-online-first.pdf\n",
      "\t https://repository.kaust.edu.sa/bitstream/10754/680934.1/1/2208.13592.pdf\n",
      "Optimal gradient sliding and its application to optimal distributed optimization under similarity\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2022/hash/d88f6f81e1aaf606776ffdd06fdf24ef-Abstract-Conference.html\n",
      "\t https://arxiv.org/abs/2205.15136\n",
      "\t https://labmmo.ru/upload/000/u8/5/3/1749-optimal-gradient-sliding-and-i.pdf\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3600270.3602697\n",
      "\t https://papers.neurips.cc/paper_files/paper/2022/file/d88f6f81e1aaf606776ffdd06fdf24ef-Paper-Conference.pdf\n",
      "\t https://ui.adsabs.harvard.edu/abs/2022arXiv220515136K/abstract\n",
      "\t https://openreview.net/forum?id=QrK0WDLVHZt\n",
      "\t https://repository.kaust.edu.sa/bitstream/10754/678602/1/2205.15136.pdf\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/49b0e2d7-321a-4563-9919-bdbef75a2d03/content\n",
      "The first optimal algorithm for smooth and strongly-convex-strongly-concave minimax optimization\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2022/hash/5e2ed801f62102f531d109d7c6e1b62f-Abstract-Conference.html\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2022/file/5e2ed801f62102f531d109d7c6e1b62f-Supplemental-Conference.pdf\n",
      "\t https://arxiv.org/abs/2205.05653\n",
      "\t https://labmmo.ru/upload/000/u8/f/7/2205-05653.pdf\n",
      "\t https://repository.kaust.edu.sa/handle/10754/677973\n",
      "\t https://ui.adsabs.harvard.edu/abs/2022arXiv220505653K/abstract\n",
      "\t https://openreview.net/forum?id=pD5Pl5hen_g\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3600270.3601338\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/242575fb-ca9c-4dee-b1f5-1eff8963d6b5/content\n",
      "Variance reduced coordinate descent with acceleration: New method with a surprising application to finite-sum problems\n",
      "\t https://proceedings.mlr.press/v119/hanzely20b.html\n",
      "\t https://repository.kaust.edu.sa/handle/10754/666019\n",
      "\t https://ui.adsabs.harvard.edu/abs/2020arXiv200204670H/abstract\n",
      "\t http://proceedings.mlr.press/v119/hanzely20b/hanzely20b-supp.pdf\n",
      "\t https://arxiv.org/abs/2002.04670\n",
      "\t https://elibrary.ru/item.asp?id=45957891\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3524938.3525316\n",
      "\t https://repository.kaust.edu.sa/bitstreams/7039c4f0-fde4-4d15-af90-d77de5ad3be3/download\n",
      "Fast linear convergence of randomized BFGS\n",
      "\t https://arxiv.org/abs/2002.11337\n",
      "\t https://repository.kaust.edu.sa/handle/10754/662101\n",
      "\t https://ui.adsabs.harvard.edu/abs/2020arXiv200211337K/abstract\n",
      "\t https://www.researchgate.net/profile/Robert-Gower-2/publication/339526612_Fast_Linear_Convergence_of_Randomized_BFGS/links/5edfa778299bf1d20bdb9443/Fast-Linear-Convergence-of-Randomized-BFGS.pdf\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/67773374-789f-4805-9fca-8d719335730e/content\n",
      "Near-optimal decentralized algorithms for saddle point problems over time-varying networks\n",
      "\t https://link.springer.com/chapter/10.1007/978-3-030-91059-4_18\n",
      "\t https://ui.adsabs.harvard.edu/abs/2021arXiv210705957B/abstract\n",
      "\t https://repository.kaust.edu.sa/handle/10754/670330\n",
      "\t https://link.springer.com/content/pdf/10.1007/978-3-030-91059-4.pdf#page=260\n",
      "\t https://dl.acm.org/doi/abs/10.1007/978-3-030-91059-4_18\n",
      "\t https://labmmo.ru/upload/000/u8/5/7/2107-05957.pdf\n",
      "\t https://books.google.com/books?hl=en&lr=&id=6HlMEAAAQBAJ&oi=fnd&pg=PA246&ots=aRod_JtBUj&sig=pruybKc0NF7OU-91woF1xrGzTZw\n",
      "\t https://arxiv.org/abs/2107.05957\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/f87dc34c-5e44-40e4-9209-4c8f8e6887ff/content\n",
      "\t https://repository.kaust.edu.sa/bitstream/10754/670330.1/1/Preprintfile1.pdf\n",
      "Stochastic spectral and conjugate descent methods\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2018/hash/e721a54a8cf18c8543d44782d9ef681f-Abstract.html\n",
      "\t https://ui.adsabs.harvard.edu/abs/2018arXiv180203703K/abstract\n",
      "\t http://papers.neurips.cc/paper/7596-stochastic-spectral-and-conjugate-descent-methods.pdf\n",
      "\t https://repository.kaust.edu.sa/handle/10754/627183\n",
      "\t https://arxiv.org/abs/1802.03703\n",
      "\t https://www.dmitry-kovalev.com/posts/ssd_talk_march_2019/ssd.pdf\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3327144.3327255\n",
      "\t https://www.researchgate.net/profile/Eduard-Gorbunov/publication/323141815_Stochastic_Spectral_and_Conjugate_Descent_Methods/links/5ae987fb45851588dd820f3c/Stochastic-Spectral-and-Conjugate-Descent-Methods.pdf\n",
      "\t https://richtarik.org/posters/Poster-SSCD.pdf\n",
      "\t https://elibrary.ru/item.asp?id=38676976\n",
      "\t https://proceedings.neurips.cc/paper/2018/hash/e721a54a8cf18c8543d44782d9ef681f-Abstract.html\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/b094154a-c56f-4e82-922a-c020628b4374/content\n",
      "Communication acceleration of local gradient methods via an accelerated primal-dual algorithm with an inexact prox\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2022/hash/88c3c482430a62d35e03926a22e4b67e-Abstract-Conference.html\n",
      "\t https://proceedings.neurips.cc/paper_files/paper/2022/file/88c3c482430a62d35e03926a22e4b67e-Supplemental-Conference.pdf\n",
      "\t https://arxiv.org/abs/2207.03957\n",
      "\t https://ui.adsabs.harvard.edu/abs/2022arXiv220703957S/abstract\n",
      "\t https://repository.kaust.edu.sa/handle/10754/679905\n",
      "\t https://openreview.net/forum?id=W72rB0wwLVu\n",
      "\t https://papers.neurips.cc/paper_files/paper/2022/file/88c3c482430a62d35e03926a22e4b67e-Supplemental-Conference.pdf\n",
      "\t https://richtarik.org/papers/APDA_Inexact_Prox.pdf\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3600270.3601853\n",
      "\t https://papers.neurips.cc/paper_files/paper/2022/file/88c3c482430a62d35e03926a22e4b67e-Paper-Conference.pdf\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/d6ec3d8a-67f3-4a37-a713-a3cf0c317e1c/content\n",
      "Decentralized saddle-point problems with different constants of strong convexity and strong concavity\n",
      "\t https://link.springer.com/article/10.1007/s10287-023-00485-9\n",
      "\t https://repository.kaust.edu.sa/items/0f028000-e96b-4fd3-9d70-175486c3b56c\n",
      "\t https://ideas.repec.org/a/spr/comgts/v21y2024i1d10.1007_s10287-023-00485-9.html\n",
      "\t https://econpapers.repec.org/article/sprcomgts/v_3a21_3ay_3a2024_3ai_3a1_3ad_3a10.1007_5fs10287-023-00485-9.htm\n",
      "\t https://ui.adsabs.harvard.edu/abs/2022arXiv220600090M/abstract\n",
      "\t https://arxiv.org/abs/2206.00090\n",
      "Decentralized Convex Optimization over Time-Varying Graphs\n",
      "\t https://link.springer.com/content/pdf/10.1007/978-3-030-54621-2_860-1.pdf\n",
      "\t https://arxiv.org/abs/2210.09719\n",
      "\t https://ui.adsabs.harvard.edu/abs/2022arXiv221009719R/abstract\n",
      "Is consensus acceleration possible in decentralized optimization over slowly time-varying networks?\n",
      "\t https://proceedings.mlr.press/v202/metelev23a.html\n",
      "\t https://ui.adsabs.harvard.edu/abs/2023arXiv230111817M/abstract\n",
      "\t https://labmmo.ru/upload/000/u8/3/1/2301-11817.pdf\n",
      "\t https://arxiv.org/abs/2301.11817\n",
      "\t https://dl.acm.org/doi/abs/10.5555/3618408.3619429\n",
      "\t http://proceedings.mlr.press/v202/metelev23a/metelev23a.pdf\n",
      "\t https://openreview.net/forum?id=DwDQNKF4oy\n",
      "On scaled methods for saddle point problems\n",
      "\t https://arxiv.org/abs/2206.08303\n",
      "\t https://dclibrary.mbzuai.ac.ae/mlfp/156/\n",
      "\t https://repository.kaust.edu.sa/handle/10754/679188\n",
      "\t https://ui.adsabs.harvard.edu/abs/2022arXiv220608303B/abstract\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/af3ba327-cd48-4690-8961-d7131807f31b/content\n",
      "Decentralized convex optimization on time-varying networks with application to Wasserstein barycenters\n",
      "\t https://repository.kaust.edu.sa/handle/10754/678603\n",
      "\t https://elibrary.ru/download/elibrary_50045117_14955880.pdf#page=156\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/1b5dd049-1d24-44fb-86f0-6d5277f2ebc8/content\n",
      "\t https://elibrary.ru/download/elibrary_50045117_78643624.pdf#page=156\n",
      "\t https://link.springer.com/article/10.1007/s10287-023-00493-9\n",
      "\t https://arxiv.org/abs/2205.15669\n",
      "\t https://europepmc.org/article/ppr/ppr688087\n",
      "\t https://ui.adsabs.harvard.edu/abs/2022arXiv220515669Y/abstract\n",
      "\t https://ideas.repec.org/a/spr/comgts/v21y2024i1d10.1007_s10287-023-00493-9.html\n",
      "\t https://econpapers.repec.org/article/sprcomgts/v_3a21_3ay_3a2024_3ai_3a1_3ad_3a10.1007_5fs10287-023-00493-9.htm\n",
      "\t https://www.researchsquare.com/article/rs-3126039/latest\n",
      "Non-smooth setting of stochastic decentralized convex optimization problem over time-varying graphs\n",
      "\t https://link.springer.com/article/10.1007/s10287-023-00479-7\n",
      "\t https://labmmo.ru/upload/000/u8/c/8/2307-00392.pdf\n",
      "\t https://www.researchgate.net/profile/Aleksandr-Lobanov-6/publication/372074109_Non-Smooth_Setting_of_Stochastic_Decentralized_Convex_Optimization_Problem_Over_Time-Varying_Graphs/links/64cba034d394182ab3a10747/Non-Smooth-Setting-of-Stochastic-Decentralized-Convex-Optimization-Problem-Over-Time-Varying-Graphs.pdf\n",
      "\t https://econpapers.repec.org/article/sprcomgts/v_3a20_3ay_3a2023_3ai_3a1_3ad_3a10.1007_5fs10287-023-00479-7.htm\n",
      "\t https://ideas.repec.org/a/spr/comgts/v20y2023i1d10.1007_s10287-023-00479-7.html\n",
      "\t https://arxiv.org/abs/2307.00392\n",
      "\t https://ui.adsabs.harvard.edu/abs/2023arXiv230700392L/abstract\n",
      "A hypothesis about the rate of global convergence for optimal methods (Newton’s type) in smooth convex optimization\n",
      "\t http://crm-en.ics.org.ru/journal/article/2685/\n",
      "\t https://www.mathnet.ru/eng/crm253\n",
      "\t http://crm-en.ics.org.ru/journal/article/references/2685/\n",
      "An optimal algorithm for strongly convex min-min optimization\n",
      "\t https://arxiv.org/abs/2212.14439\n",
      "\t https://ui.adsabs.harvard.edu/abs/2022arXiv221214439G/abstract\n",
      "\t https://repository.kaust.edu.sa/items/38439283-3258-40d9-a35a-aeb3be0eb73f\n",
      "Decentralized saddle point problems via non-Euclidean mirror prox\n",
      "\t https://www.tandfonline.com/doi/abs/10.1080/10556788.2023.2280062\n",
      "\t https://repository.kaust.edu.sa/handle/10754/696834\n",
      "\t https://repository.kaust.edu.sa/items/972f8f84-000d-409a-9a3e-fbae68b9bd4a\n",
      "Decentralized Finite-Sum Optimization over Time-Varying Networks\n",
      "\t https://arxiv.org/abs/2402.02490\n",
      "\t https://ui.adsabs.harvard.edu/abs/2024arXiv240202490M/abstract\n",
      "Optimal algorithm with complexity separation for strongly convex-strongly concave composite saddle point problems\n",
      "\t https://arxiv.org/abs/2307.12946\n",
      "\t https://ui.adsabs.harvard.edu/abs/2023arXiv230712946B/abstract\n",
      "Decentralized Optimization with Coupled Constraints\n",
      "\t https://arxiv.org/abs/2407.02020\n",
      "\t https://ui.adsabs.harvard.edu/abs/2024arXiv240702020Y/abstract\n",
      "Lower Bounds and Optimal Algorithms for Non-Smooth Convex Decentralized Optimization over Time-Varying Networks\n",
      "\t https://arxiv.org/abs/2405.18031\n",
      "\t https://ui.adsabs.harvard.edu/abs/2024arXiv240518031K/abstract\n",
      "Optimal Algorithms for Affinely Constrained, Distributed, Decentralized, Minimax, and High-Order Optimization Problems\n",
      "\t https://repository.kaust.edu.sa/handle/10754/682331\n",
      "\t https://repository.kaust.edu.sa/server/api/core/bitstreams/115f71a4-0e9d-4dfe-9f09-a1434b75e39e/content\n"
     ]
    }
   ],
   "source": [
    "def split_by_year(\n",
    "    paper_list: typing.List[Paper], preprint: bool\n",
    ") -> typing.List[typing.Tuple[int, typing.List[Paper]]]:\n",
    "    paper_list.sort(reverse=preprint)\n",
    "    pd: typing.Dict[int, Paper] = {}\n",
    "    for paper in paper_list:\n",
    "        if paper.year in pd.keys():\n",
    "            pd[paper.year].append(paper)\n",
    "        else:\n",
    "            pd[paper.year] = [paper]\n",
    "    result = [(k, v) for k, v in pd.items()]\n",
    "    result.sort(reverse=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "paper_list: typing.List[Paper] = []\n",
    "publication_list = []\n",
    "preprint_list = []\n",
    "for paper_dict in paper_dict_list:\n",
    "    paper = Paper(paper_dict)\n",
    "    if paper.type == \"publication\":\n",
    "        publication_list.append(paper)\n",
    "    elif paper.type == \"preprint\":\n",
    "        preprint_list.append(paper)\n",
    "\n",
    "publication_list = split_by_year(publication_list, False)\n",
    "preprint_list = split_by_year(preprint_list, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"span-paper-title\"><a href=\"https://link.springer.com/article/10.1007/s10287-023-00493-9\">Decentralized convex optimization on time-varying networks with application to Wasserstein barycenters</a></span><span> (Olga Yufereva, Michael Persiianov, Pavel Dvurechensky, Alexander Gasnikov, Dmitry Kovalev). Computational Management Science, 2024. [<a href=\"https://link.springer.com/article/10.1007/s10287-023-00493-9\">Link</a>, <a href=\"https://arxiv.org/abs/2205.15669\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2205.15669\">PDF</a>].</span> ['<a href=\"https://link.springer.com/article/10.1007/s10287-023-00493-9\">Link</a>', '<a href=\"https://arxiv.org/abs/2205.15669\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2205.15669\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://link.springer.com/article/10.1007/s10287-023-00485-9\">Decentralized saddle-point problems with different constants of strong convexity and strong concavity</a></span><span> (Dmitry Metelev, Alexander Rogozin, Alexander Gasnikov, Dmitry Kovalev). Computational Management Science, 2024. [<a href=\"https://link.springer.com/article/10.1007/s10287-023-00485-9\">Link</a>, <a href=\"https://arxiv.org/abs/2206.00090\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2206.00090\">PDF</a>].</span> ['<a href=\"https://link.springer.com/article/10.1007/s10287-023-00485-9\">Link</a>', '<a href=\"https://arxiv.org/abs/2206.00090\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2206.00090\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://www.tandfonline.com/doi/abs/10.1080/10556788.2023.2280062\">Decentralized saddle point problems via non-Euclidean mirror prox</a></span><span> (Alexander Rogozin, Aleksandr Beznosikov, Darina Dvinskikh, Dmitry Kovalev, Pavel Dvurechensky, Alexander Gasnikov). Optimization Methods and Software, 2024. [<a href=\"https://www.tandfonline.com/doi/abs/10.1080/10556788.2023.2280062\">Link</a>].</span> ['<a href=\"https://www.tandfonline.com/doi/abs/10.1080/10556788.2023.2280062\">Link</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://link.springer.com/article/10.1007/s10287-023-00479-7\">Non-smooth setting of stochastic decentralized convex optimization problem over time-varying graphs</a></span><span> (Aleksandr Lobanov, Andrew Veprikov, Georgiy Konin, Aleksandr Beznosikov, Alexander Gasnikov, Dmitry Kovalev). Computational Management Science, 2023. [<a href=\"https://link.springer.com/article/10.1007/s10287-023-00479-7\">Link</a>, <a href=\"https://arxiv.org/abs/2307.00392\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2307.00392\">PDF</a>].</span> ['<a href=\"https://link.springer.com/article/10.1007/s10287-023-00479-7\">Link</a>', '<a href=\"https://arxiv.org/abs/2307.00392\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2307.00392\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://link.springer.com/content/pdf/10.1007/978-3-030-54621-2_860-1.pdf\">Decentralized Convex Optimization over Time-Varying Graphs</a></span><span> (Alexander Rogozin, Alexander Gasnikov, Aleksander Beznosikov, Dmitry Kovalev). Encyclopedia of Optimization, 2023. [<a href=\"https://link.springer.com/content/pdf/10.1007/978-3-030-54621-2_860-1.pdf\">Link</a>, <a href=\"https://arxiv.org/abs/2210.09719\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2210.09719\">PDF</a>].</span> ['<a href=\"https://link.springer.com/content/pdf/10.1007/978-3-030-54621-2_860-1.pdf\">Link</a>', '<a href=\"https://arxiv.org/abs/2210.09719\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2210.09719\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://ems.press/journals/mag/articles/9939904\">Smooth monotone stochastic variational inequalities and saddle point problems: A survey</a></span><span> (Aleksandr Beznosikov, Boris Polyak, Eduard Gorbunov, Dmitry Kovalev, Alexander Gasnikov). European Mathematical Society Magazine, 2023. [<a href=\"https://ems.press/journals/mag/articles/9939904\">Link</a>, <a href=\"https://arxiv.org/abs/2208.13592\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2208.13592\">PDF</a>].</span> ['<a href=\"https://ems.press/journals/mag/articles/9939904\">Link</a>', '<a href=\"https://arxiv.org/abs/2208.13592\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2208.13592\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.mlr.press/v202/metelev23a.html\">Is consensus acceleration possible in decentralized optimization over slowly time-varying networks?</a></span><span> (Dmitry Metelev, Alexander Rogozin, Dmitry Kovalev, Alexander Gasnikov). International Conference on Machine Learning, 2023. [<a href=\"https://proceedings.mlr.press/v202/metelev23a.html\">Link</a>, <a href=\"https://arxiv.org/abs/2301.11817\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2301.11817\">PDF</a>].</span> ['<a href=\"https://proceedings.mlr.press/v202/metelev23a.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2301.11817\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2301.11817\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://www.tandfonline.com/doi/abs/10.1080/10556788.2022.2117355\">Stochastic distributed learning with gradient quantization and double-variance reduction</a></span><span> (Samuel Horváth, Dmitry Kovalev, Konstantin Mishchenko, Peter Richtárik, Sebastian Stich). Optimization Methods and Software, 2023. [<a href=\"https://www.tandfonline.com/doi/abs/10.1080/10556788.2022.2117355\">Link</a>, <a href=\"https://arxiv.org/abs/1904.05115\">arXiv</a>, <a href=\"https://arxiv.org/pdf/1904.05115\">PDF</a>].</span> ['<a href=\"https://www.tandfonline.com/doi/abs/10.1080/10556788.2022.2117355\">Link</a>', '<a href=\"https://arxiv.org/abs/1904.05115\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/1904.05115\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/883f66687a521536c505f9b2fbdcbf1e-Abstract-Conference.html\">Accelerated primal-dual gradient method for smooth and convex-concave saddle-point problems with bilinear coupling</a></span><span> (Dmitry Kovalev, Alexander Gasnikov, Peter Richtárik). Advances in Neural Information Processing Systems, 2022. [<a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/883f66687a521536c505f9b2fbdcbf1e-Abstract-Conference.html\">Link</a>, <a href=\"https://arxiv.org/abs/2112.15199\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2112.15199\">PDF</a>].</span> ['<a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/883f66687a521536c505f9b2fbdcbf1e-Abstract-Conference.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2112.15199\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2112.15199\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/88c3c482430a62d35e03926a22e4b67e-Abstract-Conference.html\">Communication acceleration of local gradient methods via an accelerated primal-dual algorithm with an inexact prox</a></span><span> (Abdurakhmon Sadiev, Dmitry Kovalev, Peter Richtárik). Advances in Neural Information Processing Systems, 2022. [<a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/88c3c482430a62d35e03926a22e4b67e-Abstract-Conference.html\">Link</a>, <a href=\"https://arxiv.org/abs/2207.03957\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2207.03957\">PDF</a>].</span> ['<a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/88c3c482430a62d35e03926a22e4b67e-Abstract-Conference.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2207.03957\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2207.03957\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/c959bb2cb164d37569a17fa67494d69a-Abstract-Conference.html\">Optimal algorithms for decentralized stochastic variational inequalities</a></span><span> (Dmitry Kovalev, Aleksandr Beznosikov, Abdurakhmon Sadiev, Michael Persiianov, Peter Richtárik, Alexander Gasnikov). Advances in Neural Information Processing Systems, 2022. [<a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/c959bb2cb164d37569a17fa67494d69a-Abstract-Conference.html\">Link</a>, <a href=\"https://arxiv.org/abs/2202.02771\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2202.02771\">PDF</a>].</span> ['<a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/c959bb2cb164d37569a17fa67494d69a-Abstract-Conference.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2202.02771\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2202.02771\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/d88f6f81e1aaf606776ffdd06fdf24ef-Abstract-Conference.html\">Optimal gradient sliding and its application to optimal distributed optimization under similarity</a></span><span> (Dmitry Kovalev, Aleksandr Beznosikov, Ekaterina Borodich, Alexander Gasnikov, Gesualdo Scutari). Advances in Neural Information Processing Systems, 2022. [<a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/d88f6f81e1aaf606776ffdd06fdf24ef-Abstract-Conference.html\">Link</a>, <a href=\"https://arxiv.org/abs/2205.15136\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2205.15136\">PDF</a>].</span> ['<a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/d88f6f81e1aaf606776ffdd06fdf24ef-Abstract-Conference.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2205.15136\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2205.15136\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/e56f394bbd4f0ec81393d767caa5a31b-Abstract-Conference.html\">The first optimal acceleration of high-order methods in smooth convex optimization</a></span><span> (Dmitry Kovalev, Alexander Gasnikov). Advances in Neural Information Processing Systems, 2022. [<a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/e56f394bbd4f0ec81393d767caa5a31b-Abstract-Conference.html\">Link</a>, <a href=\"https://arxiv.org/abs/2205.09647\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2205.09647\">PDF</a>].</span> ['<a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/e56f394bbd4f0ec81393d767caa5a31b-Abstract-Conference.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2205.09647\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2205.09647\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/5e2ed801f62102f531d109d7c6e1b62f-Abstract-Conference.html\">The first optimal algorithm for smooth and strongly-convex-strongly-concave minimax optimization</a></span><span> (Dmitry Kovalev, Alexander Gasnikov). Advances in Neural Information Processing Systems, 2022. [<a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/5e2ed801f62102f531d109d7c6e1b62f-Abstract-Conference.html\">Link</a>, <a href=\"https://arxiv.org/abs/2205.05653\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2205.05653\">PDF</a>].</span> ['<a href=\"https://proceedings.neurips.cc/paper_files/paper/2022/hash/5e2ed801f62102f531d109d7c6e1b62f-Abstract-Conference.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2205.05653\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2205.05653\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"http://crm-en.ics.org.ru/uploads/crmissues/crm_2023_02/22_tominin.pdf\">Accelerated variance-reduced methods for saddle-point problems</a></span><span> (Ekaterina Borodich, Vladislav Tominin, Yaroslav Tominin, Dmitry Kovalev, Alexander Gasnikov, Pavel Dvurechensky). EURO Journal on Computational Optimization, 2022. [<a href=\"http://crm-en.ics.org.ru/uploads/crmissues/crm_2023_02/22_tominin.pdf\">Link</a>, <a href=\"https://arxiv.org/abs/2103.09344\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2103.09344\">PDF</a>].</span> ['<a href=\"http://crm-en.ics.org.ru/uploads/crmissues/crm_2023_02/22_tominin.pdf\">Link</a>', '<a href=\"https://arxiv.org/abs/2103.09344\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2103.09344\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.mlr.press/v151/salim22a.html\">An optimal algorithm for strongly convex minimization under affine constraints</a></span><span> (Adil Salim, Laurent Condat, Dmitry Kovalev, Peter Richtárik). International Conference on Artificial Intelligence and Statistics, 2022. [<a href=\"https://proceedings.mlr.press/v151/salim22a.html\">Link</a>, <a href=\"https://arxiv.org/abs/2102.11079\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2102.11079\">PDF</a>].</span> ['<a href=\"https://proceedings.mlr.press/v151/salim22a.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2102.11079\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2102.11079\">PDF</a>']\n",
      "<span class=\"span-paper-title\">IntSGD: Adaptive floatless compression of stochastic gradients</span><span> (Konstantin Mishchenko, Bokun Wang, Dmitry Kovalev, Peter Richtárik). International Conference on Learning Representations, 2022. [<a href=\"https://arxiv.org/abs/2102.08374\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2102.08374\">PDF</a>].</span> ['<a href=\"https://arxiv.org/abs/2102.08374\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2102.08374\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.neurips.cc/paper/2021/hash/bc37e109d92bdc1ea71da6c919d54907-Abstract.html\">Lower bounds and optimal algorithms for smooth and strongly convex decentralized optimization over time-varying networks</a></span><span> (Dmitry Kovalev, Elnur Gasanov, Alexander Gasnikov, Peter Richtarik). Advances in Neural Information Processing Systems, 2021. [<a href=\"https://proceedings.neurips.cc/paper/2021/hash/bc37e109d92bdc1ea71da6c919d54907-Abstract.html\">Link</a>, <a href=\"https://arxiv.org/abs/2106.04469\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2106.04469\">PDF</a>].</span> ['<a href=\"https://proceedings.neurips.cc/paper/2021/hash/bc37e109d92bdc1ea71da6c919d54907-Abstract.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2106.04469\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2106.04469\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.mlr.press/v130/kovalev21a.html\">A linearly convergent algorithm for decentralized optimization: Sending less bits for free!</a></span><span> (Dmitry Kovalev, Anastasia Koloskova, Martin Jaggi, Peter Richtarik, Sebastian Stich). International Conference on Artificial Intelligence and Statistics, 2021. [<a href=\"https://proceedings.mlr.press/v130/kovalev21a.html\">Link</a>, <a href=\"https://arxiv.org/abs/2011.01697\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2011.01697\">PDF</a>].</span> ['<a href=\"https://proceedings.mlr.press/v130/kovalev21a.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2011.01697\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2011.01697\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"http://proceedings.mlr.press/v139/kovalev21a\">ADOM: accelerated decentralized optimization method for time-varying networks</a></span><span> (Dmitry Kovalev, Egor Shulgin, Peter Richtárik, Alexander V Rogozin, Alexander Gasnikov). International Conference on Machine Learning, 2021. [<a href=\"http://proceedings.mlr.press/v139/kovalev21a\">Link</a>, <a href=\"https://arxiv.org/abs/2102.09234\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2102.09234\">PDF</a>].</span> ['<a href=\"http://proceedings.mlr.press/v139/kovalev21a\">Link</a>', '<a href=\"https://arxiv.org/abs/2102.09234\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2102.09234\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://link.springer.com/chapter/10.1007/978-3-030-91059-4_18\">Near-optimal decentralized algorithms for saddle point problems over time-varying networks</a></span><span> (Aleksandr Beznosikov, Alexander Rogozin, Dmitry Kovalev, Alexander Gasnikov). Optimization and Applications: 12th International Conference, OPTIMA 2021, Petrovac, Montenegro, September 27–October 1, 2021, Proceedings 12, 2021. [<a href=\"https://link.springer.com/chapter/10.1007/978-3-030-91059-4_18\">Link</a>, <a href=\"https://arxiv.org/abs/2107.05957\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2107.05957\">PDF</a>].</span> ['<a href=\"https://link.springer.com/chapter/10.1007/978-3-030-91059-4_18\">Link</a>', '<a href=\"https://arxiv.org/abs/2107.05957\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2107.05957\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://link.springer.com/chapter/10.1007/978-3-030-91059-4_19\">Towards accelerated rates for distributed optimization over time-varying networks</a></span><span> (Alexander Rogozin, Vladislav Lukoshkin, Alexander Gasnikov, Dmitry Kovalev, Egor Shulgin). Optimization and Applications: 12th International Conference, OPTIMA 2021, Petrovac, Montenegro, September 27–October 1, 2021, Proceedings 12, 2021. [<a href=\"https://link.springer.com/chapter/10.1007/978-3-030-91059-4_19\">Link</a>, <a href=\"https://arxiv.org/abs/2009.11069\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2009.11069\">PDF</a>].</span> ['<a href=\"https://link.springer.com/chapter/10.1007/978-3-030-91059-4_19\">Link</a>', '<a href=\"https://arxiv.org/abs/2009.11069\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2009.11069\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.neurips.cc/paper_files/paper/2020/hash/ef9280fbc5317f17d480e4d4f61b3751-Abstract.html\">Linearly converging error compensated SGD</a></span><span> (Eduard Gorbunov, Dmitry Kovalev, Dmitry Makarenko, Peter Richtárik). Advances in Neural Information Processing Systems, 2020. [<a href=\"https://proceedings.neurips.cc/paper_files/paper/2020/hash/ef9280fbc5317f17d480e4d4f61b3751-Abstract.html\">Link</a>, <a href=\"https://arxiv.org/abs/2010.12292\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2010.12292\">PDF</a>].</span> ['<a href=\"https://proceedings.neurips.cc/paper_files/paper/2020/hash/ef9280fbc5317f17d480e4d4f61b3751-Abstract.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2010.12292\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2010.12292\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.neurips.cc/paper_files/paper/2020/hash/d530d454337fb09964237fecb4bea6ce-Abstract.html\">Optimal and practical algorithms for smooth and strongly convex decentralized optimization</a></span><span> (Dmitry Kovalev, Adil Salim, Peter Richtárik). Advances in Neural Information Processing Systems, 2020. [<a href=\"https://proceedings.neurips.cc/paper_files/paper/2020/hash/d530d454337fb09964237fecb4bea6ce-Abstract.html\">Link</a>, <a href=\"https://arxiv.org/abs/2006.11773\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2006.11773\">PDF</a>].</span> ['<a href=\"https://proceedings.neurips.cc/paper_files/paper/2020/hash/d530d454337fb09964237fecb4bea6ce-Abstract.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2006.11773\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2006.11773\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.mlr.press/v117/kovalev20a.html\">Don’t jump through hoops and remove those loops: SVRG and Katyusha are better without the outer loop</a></span><span> (Dmitry Kovalev, Samuel Horváth, Peter Richtárik). Algorithmic Learning Theory, 2020. [<a href=\"https://proceedings.mlr.press/v117/kovalev20a.html\">Link</a>, <a href=\"https://arxiv.org/abs/1901.08689\">arXiv</a>, <a href=\"https://arxiv.org/pdf/1901.08689\">PDF</a>].</span> ['<a href=\"https://proceedings.mlr.press/v117/kovalev20a.html\">Link</a>', '<a href=\"https://arxiv.org/abs/1901.08689\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/1901.08689\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://link.springer.com/article/10.1134/S0965542520110020\">Accelerated methods for saddle-point problem</a></span><span> (Mohammad S Alkousa, Alexander Vladimirovich Gasnikov, Darina Mikhailovna Dvinskikh, Dmitry A Kovalev, Fedor Sergeevich Stonyakin). Computational Mathematics and Mathematical Physics, 2020. [<a href=\"https://link.springer.com/article/10.1134/S0965542520110020\">Link</a>, <a href=\"https://arxiv.org/abs/1906.03620\">arXiv</a>, <a href=\"https://arxiv.org/pdf/1906.03620\">PDF</a>].</span> ['<a href=\"https://link.springer.com/article/10.1134/S0965542520110020\">Link</a>', '<a href=\"https://arxiv.org/abs/1906.03620\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/1906.03620\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"http://proceedings.mlr.press/v108/mishchenko20a\">Revisiting stochastic extragradient</a></span><span> (Konstantin Mishchenko, Dmitry Kovalev, Egor Shulgin, Peter Richtárik, Yura Malitsky). International Conference on Artificial Intelligence and Statistics, 2020. [<a href=\"http://proceedings.mlr.press/v108/mishchenko20a\">Link</a>, <a href=\"https://arxiv.org/abs/1905.11373\">arXiv</a>, <a href=\"https://arxiv.org/pdf/1905.11373\">PDF</a>].</span> ['<a href=\"http://proceedings.mlr.press/v108/mishchenko20a\">Link</a>', '<a href=\"https://arxiv.org/abs/1905.11373\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/1905.11373\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.mlr.press/v119/li20g.html\">Acceleration for compressed gradient descent in distributed and federated optimization</a></span><span> (Zhize Li, Dmitry Kovalev, Xun Qian, Peter Richtarik). International Conference on Machine Learning, 2020. [<a href=\"https://proceedings.mlr.press/v119/li20g.html\">Link</a>, <a href=\"https://arxiv.org/abs/2002.11364\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2002.11364\">PDF</a>].</span> ['<a href=\"https://proceedings.mlr.press/v119/li20g.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2002.11364\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2002.11364\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"http://proceedings.mlr.press/v119/malinovskiy20a.html\">From local SGD to local fixed-point methods for federated learning</a></span><span> (Grigory Malinovskiy, Dmitry Kovalev, Elnur Gasanov, Laurent Condat, Peter Richtarik). International Conference on Machine Learning, 2020. [<a href=\"http://proceedings.mlr.press/v119/malinovskiy20a.html\">Link</a>, <a href=\"https://arxiv.org/abs/2004.01442\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2004.01442\">PDF</a>].</span> ['<a href=\"http://proceedings.mlr.press/v119/malinovskiy20a.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2004.01442\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2004.01442\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.mlr.press/v119/hanzely20b.html\">Variance reduced coordinate descent with acceleration: New method with a surprising application to finite-sum problems</a></span><span> (Filip Hanzely, Dmitry Kovalev, Peter Richtarik). International Conference on Machine Learning, 2020. [<a href=\"https://proceedings.mlr.press/v119/hanzely20b.html\">Link</a>, <a href=\"https://arxiv.org/abs/2002.04670\">arXiv</a>, <a href=\"https://arxiv.org/pdf/2002.04670\">PDF</a>].</span> ['<a href=\"https://proceedings.mlr.press/v119/hanzely20b.html\">Link</a>', '<a href=\"https://arxiv.org/abs/2002.04670\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/2002.04670\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.neurips.cc/paper/2019/hash/bc6dc48b743dc5d013b1abaebd2faed2-Abstract.html\">RSN: randomized subspace Newton</a></span><span> (Robert Gower, Dmitry Kovalev, Felix Lieder, Peter Richtárik). Advances in Neural Information Processing Systems, 2019. [<a href=\"https://proceedings.neurips.cc/paper/2019/hash/bc6dc48b743dc5d013b1abaebd2faed2-Abstract.html\">Link</a>, <a href=\"https://arxiv.org/abs/1905.10874\">arXiv</a>, <a href=\"https://arxiv.org/pdf/1905.10874\">PDF</a>].</span> ['<a href=\"https://proceedings.neurips.cc/paper/2019/hash/bc6dc48b743dc5d013b1abaebd2faed2-Abstract.html\">Link</a>', '<a href=\"https://arxiv.org/abs/1905.10874\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/1905.10874\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.neurips.cc/paper/2019/hash/6a8018b3a00b69c008601b8becae392b-Abstract.html\">Stochastic proximal langevin algorithm: Potential splitting and nonasymptotic rates</a></span><span> (Adil Salim, Dmitry Kovalev, Peter Richtárik). Advances in Neural Information Processing Systems, 2019. [<a href=\"https://proceedings.neurips.cc/paper/2019/hash/6a8018b3a00b69c008601b8becae392b-Abstract.html\">Link</a>, <a href=\"https://arxiv.org/abs/1905.11768\">arXiv</a>, <a href=\"https://arxiv.org/pdf/1905.11768\">PDF</a>].</span> ['<a href=\"https://proceedings.neurips.cc/paper/2019/hash/6a8018b3a00b69c008601b8becae392b-Abstract.html\">Link</a>', '<a href=\"https://arxiv.org/abs/1905.11768\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/1905.11768\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://proceedings.neurips.cc/paper_files/paper/2018/hash/e721a54a8cf18c8543d44782d9ef681f-Abstract.html\">Stochastic spectral and conjugate descent methods</a></span><span> (Dmitry Kovalev, Peter Richtárik, Eduard Gorbunov, Elnur Gasanov). Advances in Neural Information Processing Systems, 2018. [<a href=\"https://proceedings.neurips.cc/paper_files/paper/2018/hash/e721a54a8cf18c8543d44782d9ef681f-Abstract.html\">Link</a>, <a href=\"https://arxiv.org/abs/1802.03703\">arXiv</a>, <a href=\"https://arxiv.org/pdf/1802.03703\">PDF</a>].</span> ['<a href=\"https://proceedings.neurips.cc/paper_files/paper/2018/hash/e721a54a8cf18c8543d44782d9ef681f-Abstract.html\">Link</a>', '<a href=\"https://arxiv.org/abs/1802.03703\">arXiv</a>', '<a href=\"https://arxiv.org/pdf/1802.03703\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"http://crm-en.ics.org.ru/journal/article/2685/\">A hypothesis about the rate of global convergence for optimal methods (Newton’s type) in smooth convex optimization</a></span><span> (Alexander Gasnikov, Dmitry Kovalev). Computer research and modeling, 2018. [<a href=\"http://crm-en.ics.org.ru/journal/article/2685/\">Link</a>].</span> ['<a href=\"http://crm-en.ics.org.ru/journal/article/2685/\">Link</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://arxiv.org/abs/2407.02020\">Decentralized Optimization with Coupled Constraints</a></span><span> (Demyan Yarmoshik, Dmitry Kovalev, Alexander Rogozin, Nikita Kiselev, Daniil Dorin, Alexander Gasnikov). arXiv preprint arXiv:2407.02020, 2024. [<a href=\"https://arxiv.org/abs/2407.02020\">Link</a>, <a href=\"https://arxiv.org/pdf/2407.02020\">PDF</a>].</span> ['<a href=\"https://arxiv.org/abs/2407.02020\">Link</a>', '<a href=\"https://arxiv.org/pdf/2407.02020\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://arxiv.org/abs/2405.18031\">Lower Bounds and Optimal Algorithms for Non-Smooth Convex Decentralized Optimization over Time-Varying Networks</a></span><span> (Dmitry Kovalev, Ekaterina Borodich, Alexander Gasnikov, Dmitrii Feoktistov). arXiv preprint arXiv:2405.18031, 2024. [<a href=\"https://arxiv.org/abs/2405.18031\">Link</a>, <a href=\"https://arxiv.org/pdf/2405.18031\">PDF</a>].</span> ['<a href=\"https://arxiv.org/abs/2405.18031\">Link</a>', '<a href=\"https://arxiv.org/pdf/2405.18031\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://arxiv.org/abs/2402.02490\">Decentralized Finite-Sum Optimization over Time-Varying Networks</a></span><span> (Dmitry Metelev, Savelii Chezhegov, Alexander Rogozin, Dmitry Kovalev, Aleksandr Beznosikov, Alexander Sholokhov, Alexander Gasnikov). arXiv preprint arXiv:2402.02490, 2024. [<a href=\"https://arxiv.org/abs/2402.02490\">Link</a>, <a href=\"https://arxiv.org/pdf/2402.02490\">PDF</a>].</span> ['<a href=\"https://arxiv.org/abs/2402.02490\">Link</a>', '<a href=\"https://arxiv.org/pdf/2402.02490\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://arxiv.org/abs/2307.12946\">Optimal algorithm with complexity separation for strongly convex-strongly concave composite saddle point problems</a></span><span> (Ekaterina Borodich, Georgiy Kormakov, Dmitry Kovalev, Aleksandr Beznosikov, Alexander Gasnikov). arXiv preprint arXiv:2307.12946, 2023. [<a href=\"https://arxiv.org/abs/2307.12946\">Link</a>, <a href=\"https://arxiv.org/pdf/2307.12946\">PDF</a>].</span> ['<a href=\"https://arxiv.org/abs/2307.12946\">Link</a>', '<a href=\"https://arxiv.org/pdf/2307.12946\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://arxiv.org/abs/2212.14439\">An optimal algorithm for strongly convex min-min optimization</a></span><span> (Alexander Gasnikov, Dmitry Kovalev, Grigory Malinovsky). arXiv preprint arXiv:2212.14439, 2022. [<a href=\"https://arxiv.org/abs/2212.14439\">Link</a>, <a href=\"https://arxiv.org/pdf/2212.14439\">PDF</a>].</span> ['<a href=\"https://arxiv.org/abs/2212.14439\">Link</a>', '<a href=\"https://arxiv.org/pdf/2212.14439\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://arxiv.org/abs/2206.08303\">On scaled methods for saddle point problems</a></span><span> (Aleksandr Beznosikov, Aibek Alanov, Dmitry Kovalev, Martin Takáč, Alexander Gasnikov). arXiv preprint arXiv:2206.08303, 2022. [<a href=\"https://arxiv.org/abs/2206.08303\">Link</a>, <a href=\"https://arxiv.org/pdf/2206.08303\">PDF</a>].</span> ['<a href=\"https://arxiv.org/abs/2206.08303\">Link</a>', '<a href=\"https://arxiv.org/pdf/2206.08303\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://arxiv.org/abs/2102.07758\">Decentralized distributed optimization for saddle point problems</a></span><span> (Alexander Rogozin, Aleksandr Beznosikov, Darina Dvinskikh, Dmitry Kovalev, Pavel Dvurechensky, Alexander Gasnikov). arXiv preprint arXiv:2102.07758, 2021. [<a href=\"https://arxiv.org/abs/2102.07758\">Link</a>, <a href=\"https://arxiv.org/pdf/2102.07758\">PDF</a>].</span> ['<a href=\"https://arxiv.org/abs/2102.07758\">Link</a>', '<a href=\"https://arxiv.org/pdf/2102.07758\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://arxiv.org/abs/2002.11337\">Fast linear convergence of randomized BFGS</a></span><span> (Dmitry Kovalev, Robert M Gower, Peter Richtárik, Alexander Rogozin). arXiv preprint arXiv:2002.11337, 2020. [<a href=\"https://arxiv.org/abs/2002.11337\">Link</a>, <a href=\"https://arxiv.org/pdf/2002.11337\">PDF</a>].</span> ['<a href=\"https://arxiv.org/abs/2002.11337\">Link</a>', '<a href=\"https://arxiv.org/pdf/2002.11337\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://arxiv.org/abs/1912.09925\">Distributed fixed point methods with compressed iterates</a></span><span> (Sélim Chraibi, Ahmed Khaled, Dmitry Kovalev, Peter Richtárik, Adil Salim, Martin Takáč). arXiv preprint arXiv:1912.09925, 2019. [<a href=\"https://arxiv.org/abs/1912.09925\">Link</a>, <a href=\"https://arxiv.org/pdf/1912.09925\">PDF</a>].</span> ['<a href=\"https://arxiv.org/abs/1912.09925\">Link</a>', '<a href=\"https://arxiv.org/pdf/1912.09925\">PDF</a>']\n",
      "<span class=\"span-paper-title\"><a href=\"https://arxiv.org/abs/1912.01597\">Stochastic Newton and cubic Newton methods with simple local linear-quadratic rates</a></span><span> (Dmitry Kovalev, Konstantin Mishchenko, Peter Richtárik). arXiv preprint arXiv:1912.01597, 2019. [<a href=\"https://arxiv.org/abs/1912.01597\">Link</a>, <a href=\"https://arxiv.org/pdf/1912.01597\">PDF</a>].</span> ['<a href=\"https://arxiv.org/abs/1912.01597\">Link</a>', '<a href=\"https://arxiv.org/pdf/1912.01597\">PDF</a>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "75511"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_loader = jinja2.FileSystemLoader(\"\")\n",
    "env = jinja2.Environment(loader=file_loader)\n",
    "template = env.get_template(\"template_index.html\")\n",
    "\n",
    "output = template.render(\n",
    "    publications=publication_list,\n",
    "    preprints=preprint_list,\n",
    ")\n",
    "open(\"index.html\", \"w\").write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"CV2/date.tex\", \"w\") as file:\n",
    "    file.write(\"\\\\begin{center}\\n\")\n",
    "    file.write(\n",
    "        \"Last Updated on {}\\n\".format(datetime.datetime.now().strftime(\"%B %d, %Y\"))\n",
    "    )\n",
    "    file.write(\"\\\\end{center}\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"CV2/papers.tex\", \"w\") as file:\n",
    "    file.write(\"\\\\section{Publications}\\n\")\n",
    "    file.write(\"\\\\begin{enumerate}\\n\")\n",
    "\n",
    "    for year, paper_list in publication_list:\n",
    "        for paper in paper_list:\n",
    "            file.write(\"\\\\item\\n\")\n",
    "            file.write(f\"{paper.to_latex()}\\n\")\n",
    "\n",
    "    file.write(\"\\\\end{enumerate}\\n\")\n",
    "\n",
    "    file.write(\"\\\\section{Preprints}\\n\")\n",
    "    file.write(\"\\\\begin{enumerate}\\n\")\n",
    "\n",
    "    for year, paper_list in preprint_list:\n",
    "        for paper in paper_list:\n",
    "            file.write(\"\\\\item\\n\")\n",
    "            file.write(f\"{paper.to_latex()}\\n\")\n",
    "\n",
    "    file.write(\"\\\\end{enumerate}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
